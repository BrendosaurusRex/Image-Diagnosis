{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold = np.nan, linewidth = 115)\n",
    "import pickle\n",
    "import keras\n",
    "from keras import models, optimizers, layers, regularizers, metrics, losses\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU, ReLU, ThresholdedReLU\n",
    "from keras.layers.core import Dense, Dropout, SpatialDropout2D, Activation\n",
    "from keras.layers.convolutional import Conv2D, SeparableConv2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import model_from_json, Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Save Comparison model\n",
    "def save_model(model_name, hist_str, model_str):\n",
    "\n",
    "    pickle.dump(model_name.history, open('Training Histories/'+ hist_str + '.p', 'wb'))\n",
    "    \n",
    "    print(\"Saved \" + hist_str + \" to Training Histories folder\")\n",
    "    \n",
    "    # serialize model to JSON\n",
    "    model_name = model.to_json()\n",
    "    with open(\"CNN Models/\" + model_str + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_name)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Saved \" + model_str + \" and weights to CNN Models folder\")\n",
    "    \n",
    "# Load model architecture and weights NOTE: must compile again\n",
    "def load_model():\n",
    "    model_str = str(input(\"Name of model to load: \"))\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open('CNN Models/' + model_str + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Loaded \" + model_str + \" and weights from CNN Models folder\")\n",
    "    \n",
    "    return loaded_model\n",
    "    \n",
    "# Load history object\n",
    "def load_history():\n",
    "    hist_str = str(input(\"Name of history to load: \"))\n",
    "\n",
    "    loaded_history = pickle.load(open('Training Histories/' + hist_str + '.p', 'rb'))\n",
    "    \n",
    "    print(\"Loaded \" + hist_str + \" from Training Histories folder\")\n",
    "    \n",
    "    return loaded_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with pickle instead of processing images again\n",
    "training_img_1 = pickle.load(open('1vAll_img_res_Infiltration_1st_half.p', 'rb'))\n",
    "training_img_2 = pickle.load(open('1vAll_img_res_Infiltration_2nd_half.p', 'rb'))\n",
    "\n",
    "training_img = np.append(training_img_1, training_img_2, axis = 0)\n",
    "\n",
    "test_img = pickle.load(open('pickle_test_img.p', 'rb'))\n",
    "\n",
    "labels_1 = pickle.load(open('1vAll_labels_res_Infiltration_1st_half.p', 'rb'))\n",
    "labels_2 = pickle.load(open('1vAll_labels_res_Infiltration_2nd_half.p', 'rb'))\n",
    "\n",
    "training_labels = np.append(labels_1, labels_2, axis = 0)\n",
    "\n",
    "test_labels = pickle.load(open('test_labels.p', 'rb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46184,)\n",
      "11212\n"
     ]
    }
   ],
   "source": [
    "Infiltration_labels = training_labels[:, 8]\n",
    "Infiltration_test_labels = test_labels[:, 8]\n",
    "print(Infiltration_labels.shape)\n",
    "print(len(Infiltration_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Analysis\n",
    "def true_accuracy(y_test, pred):\n",
    "    \n",
    "    pred = np.round_(pred)\n",
    "    pred = pred.astype(dtype = 'uint8')\n",
    "    \n",
    "    ft = pred == y_test\n",
    "    \n",
    "#    acc = []\n",
    "    \n",
    "#    counter = 0\n",
    "#    while counter < len(ft):\n",
    "#        if sum(ft[counter]) < 15:\n",
    "#            acc.append(0)\n",
    "#            counter += 1\n",
    "#        else:\n",
    "#           acc.append(1)\n",
    "#            counter += 1\n",
    "           \n",
    "    # Accuracy       \n",
    "    Acc = (sum(ft)/len(ft))\n",
    "    \n",
    "   # print('\\t Complete Label Accuracy: ', (Acc * 100), '%')\n",
    "    \n",
    "   # print('Sum of Fully Correct Predictions: ', sum(acc))\n",
    "   # print('\\t\\t    Total Labels: ', len(acc))\n",
    "    \n",
    "    if Acc == 0:\n",
    "        message = 'Feels Devastating (ﾉಥ益ಥ）ﾉ ┻━┻'\n",
    "        \n",
    "    elif Acc > 0 and Acc < 50:\n",
    "        message = 'Feels Awful (੭ ˃̣̣̥ ㅂ˂̣̣̥)੭ु'\n",
    "        \n",
    "    elif Acc >= 50 and Acc < 60:\n",
    "        message = 'Feels Bad (⌯˃̶᷄ ﹏ ˂̶᷄⌯)'\n",
    "        \n",
    "    elif Acc >= 60 and Acc < 70:\n",
    "        message = 'Feels Meh... ┬─┬ノ(ಠ_ಠノ)'\n",
    "    \n",
    "    elif Acc >= 70 and Acc < 80:\n",
    "        message = 'Feels Ok ʕ ·㉨·ʔ'\n",
    "    \n",
    "    elif Acc >= 80 and Acc < 90:\n",
    "        message = 'Feels Better (^._.^)ﾉ'\n",
    "        \n",
    "    elif Acc >= 90 and Acc < 95:\n",
    "        message = 'Feels Hopeful ( •́ ⍨ •̀)'\n",
    "        \n",
    "    elif Acc >= 95 and Acc < 98:\n",
    "        message = 'Feels Good ヽ|･ω･|ゞ'\n",
    "        \n",
    "    elif Acc >= 98:\n",
    "        message = 'Feels Great! ᕙ( * •̀ ᗜ •́ * )ᕗ'\n",
    "        \n",
    "    print('\\n', message)\n",
    "    \n",
    "    return Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Analysis\n",
    "def _1vAll_accuracy(y_test, pred):\n",
    "    \n",
    "    pred = np.round_(pred)\n",
    "    pred = pred.astype(dtype = 'uint8')\n",
    "    \n",
    "    ft = pred == y_test\n",
    "    \n",
    "#    acc = []\n",
    "    \n",
    "#    counter = 0\n",
    "#    while counter < len(ft):\n",
    "#        if sum(ft[counter]) < 15:\n",
    "#            acc.append(0)\n",
    "#            counter += 1\n",
    "#        else:\n",
    "#           acc.append(1)\n",
    "#            counter += 1\n",
    "           \n",
    "    # Accuracy       \n",
    "    Acc = (sum(ft)/len(ft))\n",
    "    \n",
    "   # print('\\t Complete Label Accuracy: ', (Acc * 100), '%')\n",
    "    \n",
    "   # print('Sum of Fully Correct Predictions: ', sum(acc))\n",
    "   # print('\\t\\t    Total Labels: ', len(acc))\n",
    "    accuracy = sum(Acc)/len(Acc) * 100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "og_class_weights = [{0: 1, 1: 9.69980},\n",
    "                 {0: 1, 1: 40.38905},\n",
    "                 {0: 1, 1: 24.02400},\n",
    "                 {0: 1, 1: 48.68432},\n",
    "                 {0: 1, 1: 8.41931},\n",
    "                 {0: 1, 1: 44.56280},\n",
    "                 {0: 1, 1: 66.50059},\n",
    "                 {0: 1, 1: 493.92071},\n",
    "                 {0: 1, 1: 5.63587},\n",
    "                 {0: 1, 1: 19.39121},\n",
    "                 {0: 1, 1: 1.00000},\n",
    "                 {0: 1, 1: 17.70968},\n",
    "                 {0: 1, 1: 33.12260},\n",
    "                 {0: 1, 1: 78.35080},\n",
    "                 {0: 1, 1: 21.14674}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atelectasis        = 112120 / 3790\n",
    "Cardiomegaly       = 112120 / 972\n",
    "Consolidation      = 112120 / 1188\n",
    "Edema              = 112120 / 588\n",
    "Effusion           = 112120 / 3617\n",
    "Emphysema          = 112120 / 783\n",
    "Fibrosis           = 112120 / 555\n",
    "Hernia             = 112120 / 88\n",
    "Infiltration       = 112120 / 8666\n",
    "Mass               = 112120 / 2004\n",
    "No_Finding         = 112120 / 53911\n",
    "Nodule             = 112120 / 2478\n",
    "Pleural_Thickening = 112120 / 983\n",
    "Pneumonia          = 112120 / 283\n",
    "Pneumothorax       = 112120 / 1942\n",
    "\n",
    "print('       Atelectasis Weight: ', Atelectasis)       \n",
    "print('      Cardiomegaly Weight: ', Cardiomegaly)      \n",
    "print('     Consolidation Weight: ', Consolidation)     \n",
    "print('             Edema Weight: ', Edema)             \n",
    "print('          Effusion Weight: ', Effusion)          \n",
    "print('         Emphysema Weight: ', Emphysema)         \n",
    "print('          Fibrosis Weight: ', Fibrosis)          \n",
    "print('            Hernia Weight: ', Hernia)            \n",
    "print('      Infiltration Weight: ', Infiltration)      \n",
    "print('              Mass Weight: ', Mass)              \n",
    "print('        No_Finding Weight: ', No_Finding)        \n",
    "print('            Nodule Weight: ', Nodule)            \n",
    "print('Pleural_Thickening Weight: ', Pleural_Thickening)\n",
    "print('         Pneumonia Weight: ', Pneumonia)         \n",
    "print('      Pneumothorax Weight: ', Pneumothorax)\n",
    "\n",
    "yung_class_weights = [{0: 1, 1: Atelectasis},\n",
    "                      {0: 1, 1: Cardiomegaly},\n",
    "                      {0: 1, 1: Consolidation},\n",
    "                      {0: 1, 1: Edema},\n",
    "                      {0: 1, 1: Effusion},\n",
    "                      {0: 1, 1: Emphysema},\n",
    "                      {0: 1, 1: Fibrosis},\n",
    "                      {0: 1, 1: Hernia},\n",
    "                      {0: 1, 1: Infiltration},\n",
    "                      {0: 1, 1: Mass},\n",
    "                      {0: 1, 1: No_Finding},\n",
    "                      {0: 1, 1: Nodule},\n",
    "                      {0: 1, 1: Pleural_Thickening},\n",
    "                      {0: 1, 1: Pneumonia},\n",
    "                      {0: 1, 1: Pneumothorax}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Infiltration_class_weight = [{0: 1, 1: 12.9379183014078}]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "exp_weights = [{0:1., 1: 94.086},\n",
    "              {0:1., 1: 1631.2754},\n",
    "              {0:1., 1: 577.1525},\n",
    "              {0:1., 1: 2370.163},\n",
    "              {0:1., 1: 70.8848},\n",
    "              {0:1., 1: 1985.8431},\n",
    "              {0:1., 1: 4422.3285},\n",
    "              {0:1., 1: 243957.6678},\n",
    "              {0:1., 1: 31.76303},\n",
    "              {0:1., 1: 376.019025},\n",
    "              {0:1., 1: 1.},\n",
    "              {0:1., 1: 313.63277},\n",
    "              {0:1., 1: 1097.106631},\n",
    "              {0:1., 1: 6138.84786},\n",
    "              {0:1., 1: 447.1846}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Vs. All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40411 samples, validate on 5773 samples\n",
      "Epoch 1/20\n",
      "40411/40411 [==============================] - 77s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 2/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 3/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 4/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 5/20\n",
      "40411/40411 [==============================] - 77s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 6/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 7/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 8/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 9/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 10/20\n",
      "40411/40411 [==============================] - 77s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 11/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 12/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 13/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 14/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 15/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 16/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 17/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 18/20\n",
      "40411/40411 [==============================] - 77s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 19/20\n",
      "40411/40411 [==============================] - 77s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "Epoch 20/20\n",
      "40411/40411 [==============================] - 76s 2ms/step - loss: 82.6584 - acc: 0.6036 - val_loss: 76.9768 - val_acc: 0.6309\n",
      "\t Complete Label Accuracy:  100.0 %\n",
      "Sum of Fully Correct Predictions:  11212\n",
      "\t\t    Total Labels:  11212\n",
      "\n",
      " Feels Awful (੭ ˃̣̣̥ ㅂ˂̣̣̥)੭ु\n",
      "Saved Infiltration_1vAll_20e_history to Training Histories folder\n",
      "Saved Infiltration_1vAll_20e and weights to CNN Models folder\n"
     ]
    }
   ],
   "source": [
    "# Infiltration One Vs. All\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "# Last model: Infiltration_1vAll_20e\n",
    "#model = load_model()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-3), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, Infiltration_labels, \n",
    "                      epochs = 20, \n",
    "                      validation_split = (1 / 8), \n",
    "                      batch_size = 128, verbose = 1, \n",
    "                      class_weight = Infiltration_class_weight)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(Infiltration_test_labels, Predictions)\n",
    "\n",
    "history_str = 'Infiltration_1vAll_20e_history'\n",
    "model_str   = 'Infiltration_1vAll_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = _1vAll_accuracy(Infiltration_test_labels, Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.43631823046735"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "# v3: Class Weights squared\n",
    "# v4: Resampled data\n",
    "# v5: No weights\n",
    "# v6: Using OG Class Weights\n",
    "# v7: Random Under Sample Data and using yung_class_weights\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='softmax'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "# Last model: baseline_v7_40e\n",
    "#model = load_model()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-3), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 50, initial_epoch = 40, \n",
    "                      validation_split = (1 / 9), \n",
    "                      batch_size = 128, verbose = 1, \n",
    "                      class_weight = yung_class_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v7_50e_history'\n",
    "model_str   = 'baseline_v7_50e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseline Model for reference\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 128, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_30_history'\n",
    "model_str   = 'baseline_30'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=og_class_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v2_20e_history'\n",
    "model_str   = 'baseline_v2_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "# v3: Class Weights squared\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=exp_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v3_20e_history'\n",
    "model_str   = 'baseline_v3_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "# v3: Class Weights squared\n",
    "# v4: Resampled data\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=exp_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v4_20e_history'\n",
    "model_str   = 'baseline_v4_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes Weighted based on presence in data\n",
    "# v3: Class weights squared\n",
    "# v4: Resampled data\n",
    "# v5: No weights\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v5_20e_history'\n",
    "model_str   = 'baseline_v5_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "# v3: Class Weights squared\n",
    "# v4: Resampled data\n",
    "# v5: No weights\n",
    "# v6: Using OG Class Weights\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=og_class_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v6_20e_history'\n",
    "model_str   = 'baseline_v6_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "# v4: Added Batch Normalization to all layers\n",
    "# v5: Using softmax final activation\n",
    "# v6: Sigmoid final activation, yung_class_weights, 4 Blocks + Output, 32 Neurons in Dense Layer, SELU Activations,\n",
    "#     Removed Batch Normalization, Added Dropout to Block 3\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), \n",
    "                        kernel_regularizer=regularizers.l2(0.001), \n",
    "                        activation='selu', \n",
    "                        input_shape = (IMG_SIZE, IMG_SIZE, 1)))\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='selu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "#model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='selu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='selu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='selu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='selu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.375))\n",
    "#model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='selu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='selu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(layers.BatchNormalization())\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='selu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 30, validation_split = (1 / 9), \n",
    "                      batch_size = 128, verbose = 1, \n",
    "                      class_weight = yung_class_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v6_30e_history'\n",
    "model_str   = 'vanilla_reg_VGG_v6_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG_Doppleganger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly taken from VGG16 with 2D Spatial Dropout, Dropout, and fewer Dense layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 30, validation_split = (1/9), \n",
    "                      batch_size = 128, verbose = 1)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_history'\n",
    "model_str   = 'VGG_Doppleganger_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = 0.1, batch_size = 128, verbose = 1)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_v3_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "# v3: Using Categorical Accuracy as metrics\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = 0.1, batch_size = 128)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_v3_history'\n",
    "model_str   = 'VGG_Doppleganger_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla_VGG_Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on VGG with half reg'd layers and Dropout layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v2_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v2_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v3_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v4_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v5_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v5_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "# v6: Added Batch Normalization layers to each Block\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1, class_weight= class_weights )\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v6_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v6_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = model.predict(test_img)\n",
    "print(Predictions)\n",
    "#Accuracy = true_accuracy(test_labels, Predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla_reg_VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeled after VGGNet with half reg'd layers\n",
    "vanilla_reg_VGG = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_reg_VGG.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "vanilla_reg_VGG.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "vanilla_reg_VGG.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "vanilla_reg_VGG.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "vanilla_reg_VGG.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "vanilla_reg_VGG.add(layers.Flatten())\n",
    "vanilla_reg_VGG.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "vanilla_reg_VGG.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = vanilla_reg_VGG.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_history'\n",
    "model_str   = 'vanilla_reg_VGG_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v2_history'\n",
    "model_str   = 'vanilla_reg_VGG_v2_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v3_history'\n",
    "model_str   = 'vanilla_reg_VGG_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "# v4: Added Batch Normalization to all layers\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "'''\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Predictions = Predictions.astype(dtype = 'int32')\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v4_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(SeparableConv2D(8, (3, 3), \n",
    "                          kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation = 'elu', \n",
    "                          input_shape = (256, 256, 1)))\n",
    "model.add(SeparableConv2D(8, (3, 3), \n",
    "                          kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation = 'elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), \n",
    "                 kernel_regularizer=regularizers.l2(0.001),\n",
    "                 activation = 'elu'))\n",
    "model.add(Conv2D(32, (3, 3), \n",
    "                 kernel_regularizer=regularizers.l2(0.001),\n",
    "                 activation = 'elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(64, activation = 'elu'))\n",
    "model.add(Dense(15, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-3), \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 20, validation_split = (1/9), \n",
    "                      batch_size = 128, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Predictions = Predictions.astype(dtype = 'int32')\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v4_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
