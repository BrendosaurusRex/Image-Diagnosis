{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#np.set_printoptions(threshold = np.nan, linewidth = 115)\n",
    "import pickle\n",
    "\n",
    "# Load with pickle instead of processing images again\n",
    "training_img_1 = pickle.load(open('1vAll_img_res_Infiltration_1st_half.p', 'rb'))\n",
    "training_img_2 = pickle.load(open('1vAll_img_res_Infiltration_2nd_half.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_one = np.append(training_img_1, training_img_2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_3 = pickle.load(open('1vAll_img_res_Infiltration_3rd_half.p', 'rb'))\n",
    "training_img_4 = pickle.load(open('1vAll_img_res_Infiltration_4th_half.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_two = np.append(training_img_3, training_img_4, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36298, 256, 256, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_img = np.append(training_img_one, training_img_two, axis=0)\n",
    "\n",
    "training_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_1 = pickle.load(open('1vAll_labels_res_Infiltration_1st_half.p', 'rb'))\n",
    "labels_2 = pickle.load(open('1vAll_labels_res_Infiltration_2nd_half.p', 'rb'))\n",
    "labels_3 = pickle.load(open('1vAll_labels_res_Infiltration_3rd_half.p', 'rb'))\n",
    "labels_4 = pickle.load(open('1vAll_labels_res_Infiltration_4th_half.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = np.append(labels_1, np.append(labels_2, np.append(labels_3, labels_4, axis = 0), axis = 0), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape:  (36298,)\n",
      "Length of test_labels:  3490\n",
      "No. of Infiltration Diagnoses:  18149\n"
     ]
    }
   ],
   "source": [
    "test_img = pickle.load(open('1vAll_test_img.p', 'rb'))\n",
    "test_labels = pickle.load(open('1vAll_test_labels.p', 'rb'))\n",
    "\n",
    "print('Labels shape: ', training_labels.shape)\n",
    "print('Length of test_labels: ', len(test_labels))\n",
    "print('No. of Infiltration Diagnoses: ', sum(training_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models, optimizers, layers, regularizers, metrics, losses\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU, ReLU, ThresholdedReLU\n",
    "from keras.layers.core import Dense, Dropout, SpatialDropout2D, Activation\n",
    "from keras.layers.convolutional import Conv2D, SeparableConv2D\n",
    "from keras.models import model_from_json, Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Save Comparison model\n",
    "def save_model(model_name, hist_str, model_str):\n",
    "\n",
    "    pickle.dump(model_name.history, open('Training Histories/'+ hist_str + '.p', 'wb'))\n",
    "    \n",
    "    print(\"Saved \" + hist_str + \" to Training Histories folder\")\n",
    "    \n",
    "    # serialize model to JSON\n",
    "    model_name = model.to_json()\n",
    "    with open(\"CNN Models/\" + model_str + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_name)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Saved \" + model_str + \" and weights to CNN Models folder\")\n",
    "    \n",
    "# Load model architecture and weights NOTE: must compile again\n",
    "def load_model():\n",
    "    model_str = str(input(\"Name of model to load: \"))\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open('CNN Models/' + model_str + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Loaded \" + model_str + \" and weights from CNN Models folder\")\n",
    "    \n",
    "    return loaded_model\n",
    "    \n",
    "# Load history object\n",
    "def load_history():\n",
    "    hist_str = str(input(\"Name of history to load: \"))\n",
    "\n",
    "    loaded_history = pickle.load(open('Training Histories/' + hist_str + '.p', 'rb'))\n",
    "    \n",
    "    print(\"Loaded \" + hist_str + \" from Training Histories folder\")\n",
    "    \n",
    "    return loaded_history\n",
    "\n",
    "Infiltration_class_weight = [{0: 1, 1: 12.938}]\n",
    "\n",
    "### Custom Loss function\n",
    "#from keras import backend as K\n",
    "\n",
    "#def LSEP(true_label, pred_label):\n",
    "#    return K.log(1 + K.sum(K.exp(true_label - pred_label)))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                         normalize = False,\n",
    "                         title = 'Confusion Matrix',\n",
    "                         cmap=plt.cm.Blues):\n",
    "    _fontsize = 'xx-large'\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "        print(\"Normalized Confusion Matrix\")\n",
    "    else:\n",
    "        print(\"Confusion Matrix without Normalization\")\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=_fontsize)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=15)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 45, fontsize=_fontsize) \n",
    "    plt.yticks(tick_marks, classes, fontsize=_fontsize)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.min() + 0.2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment = 'center',\n",
    "                color='white' if cm[i, j] > thresh else 'black', \n",
    "                fontsize=_fontsize)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Labels', fontsize=_fontsize)\n",
    "    plt.xlabel('Predicted Labels', fontsize=_fontsize)\n",
    "\n",
    "# Metric Analysis\n",
    "def _1vAll_accuracy(y_test, pred):\n",
    "    \n",
    "    pred = np.squeeze(pred, axis = -1)\n",
    "    pred = np.round_(pred)\n",
    "    pred = pred.astype(dtype = 'uint8')\n",
    "    \n",
    "    ft = pred == y_test\n",
    "    \n",
    "    accuracy = sum(ft)/len(ft)\n",
    "        \n",
    "    print('\\t Complete Label Accuracy: %.2f' % round((accuracy * 100), 2), '%')\n",
    "    \n",
    "    print('Sum of Fully Correct Predictions: ', sum(ft))\n",
    "    print('\\t\\t    Total Labels: ', len(ft))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Vs. All"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Residual Neural Network\n",
    "\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "img_channels = 1\n",
    "\n",
    "#\n",
    "# network params\n",
    "#\n",
    "\n",
    "cardinality = 4\n",
    "\n",
    "\n",
    "def residual_network(x):\n",
    "    \"\"\"\n",
    "    ResNeXt by default. For ResNet set `cardinality` = 1 above.\n",
    "    \n",
    "    \"\"\"\n",
    "    def add_common_layers(y):\n",
    "        #y = layers.BatchNormalization()(y)\n",
    "        y = layers.ReLU()(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def grouped_convolution(y, nb_channels, _strides):\n",
    "        # when `cardinality` == 1 this is just a standard convolution\n",
    "        if cardinality == 1:\n",
    "            return layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "        \n",
    "        assert not nb_channels % cardinality\n",
    "        _d = nb_channels // cardinality\n",
    "\n",
    "        # in a grouped convolution layer, input and output channels are divided into `cardinality` groups,\n",
    "        # and convolutions are separately performed within each group\n",
    "        groups = []\n",
    "        for j in range(cardinality):\n",
    "            group = layers.Lambda(lambda z: z[:, :, :, j * _d:j * _d + _d])(y)\n",
    "            groups.append(layers.Conv2D(_d, kernel_size=(3, 3), strides=_strides, padding='same')(group))\n",
    "            \n",
    "        # the grouped convolutional layer concatenates them as the outputs of the layer\n",
    "        y = layers.concatenate(groups)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def residual_block(y, nb_channels_in, nb_channels_out, _strides=(1, 1), _project_shortcut=False):\n",
    "        \"\"\"\n",
    "        Our network consists of a stack of residual blocks. These blocks have the same topology,\n",
    "        and are subject to two simple rules:\n",
    "        - If producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes).\n",
    "        - Each time the spatial map is down-sampled by a factor of 2, the width of the blocks is multiplied by a factor of 2.\n",
    "        \"\"\"\n",
    "        shortcut = y\n",
    "\n",
    "        # we modify the residual building block as a bottleneck design to make the network more economical\n",
    "        y = layers.Conv2D(nb_channels_in, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        # ResNeXt (identical to ResNet when `cardinality` == 1)\n",
    "        y = grouped_convolution(y, nb_channels_in, _strides=_strides)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        y = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "        # batch normalization is employed after aggregating the transformations and before adding to the shortcut\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "        if _project_shortcut or _strides != (1, 1):\n",
    "            # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n",
    "            # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "            shortcut = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        y = layers.add([shortcut, y])\n",
    "\n",
    "        # relu is performed right after each batch normalization,\n",
    "        # expect for the output of the block where relu is performed after the adding to the shortcut\n",
    "        y = layers.ReLU()(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    # conv block 1\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = add_common_layers(x)    \n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same')(x)\n",
    "    \n",
    "    # residual block\n",
    "    for i in range(3):\n",
    "        project_shortcut = (i == 0)\n",
    "        x = residual_block(x, 16, 32, _project_shortcut=project_shortcut)\n",
    "\n",
    "    # conv block 2\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = add_common_layers(x)    \n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same')(x)\n",
    "    \n",
    "    # conv block 3\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = add_common_layers(x)    \n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same')(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(4):\n",
    "        # down-sampling is performed by conv3_1, conv4_1, and conv5_1 with a stride of 2\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 32, 32, _strides=strides)\n",
    "\n",
    "    # conv4\n",
    "    for i in range(6):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 32, 64, _strides=strides)\n",
    "\n",
    "    # conv5\n",
    "    for i in range(3):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 64, 64, _strides=strides)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(16)(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "image_tensor = layers.Input(shape=(img_height, img_width, img_channels))\n",
    "network_output = residual_network(image_tensor)\n",
    "  \n",
    "model = models.Model(inputs=[image_tensor], outputs=[network_output])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 256, 256, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 528         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 128, 128, 16) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 128, 4)  0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 128, 4)  0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 128, 4)  0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 128, 4)  0           re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 4)  148         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 4)  148         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 4)  148         lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 4)  148         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 16) 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 128, 128, 16) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 32) 1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 32) 544         re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 32) 0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 128, 128, 32) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 128, 16) 528         re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 128, 128, 16) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128, 128, 4)  0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 128, 128, 4)  0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 128, 128, 4)  0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 128, 128, 4)  0           re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 4)  148         lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 4)  148         lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 4)  148         lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 4)  148         lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 16) 0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 128, 128, 16) 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 32) 544         re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 32) 0           re_lu_4[0][0]                    \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 128, 128, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 16) 528         re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 128, 128, 16) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 128, 128, 4)  0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 128, 128, 4)  0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 128, 128, 4)  0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 128, 128, 4)  0           re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 4)  148         lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 4)  148         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 4)  148         lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 4)  148         lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 16) 0           conv2d_16[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 128, 128, 16) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 32) 544         re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 32) 128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 32) 0           re_lu_7[0][0]                    \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 128, 128, 32) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 32) 9248        re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 128, 128, 32) 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 32)   9248        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 64, 64, 32)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 32)   0           re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 32)   1056        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 32, 32, 32)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 32, 32, 8)    0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 32, 32, 8)    0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 32, 32, 8)    0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 32, 32, 8)    0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 8)    584         lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 8)    584         lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 8)    584         lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 8)    584         lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 32)   0           conv2d_24[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 16, 16, 32)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 32)   1056        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 32)   1056        re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 32)   1056        re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 16, 16, 32)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 16, 16, 8)    0           re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 16, 16, 8)    0           re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 16, 16, 8)    0           re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 16, 16, 8)    0           re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 8)    584         lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 8)    584         lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 8)    584         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 8)    584         lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 32)   0           conv2d_31[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 16, 16, 32)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 32)   1056        re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           re_lu_15[0][0]                   \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 32)   1056        re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 16, 16, 32)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 16, 16, 8)    0           re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 16, 16, 8)    0           re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 16, 16, 8)    0           re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 16, 16, 8)    0           re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 8)    584         lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 8)    584         lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 8)    584         lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 8)    584         lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 32)   0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 16, 16, 32)   0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 32)   1056        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 32)   0           re_lu_18[0][0]                   \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 32)   1056        re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 16, 16, 32)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 16, 16, 8)    0           re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 16, 16, 8)    0           re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 16, 16, 8)    0           re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 16, 16, 8)    0           re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 8)    584         lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 8)    584         lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 8)    584         lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 8)    584         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 32)   0           conv2d_43[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 16, 16, 32)   0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 32)   1056        re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 32)   0           re_lu_21[0][0]                   \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 16, 16, 32)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 32)   1056        re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 16, 16, 32)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 16, 16, 8)    0           re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 16, 16, 8)    0           re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 16, 16, 8)    0           re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 16, 16, 8)    0           re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 8)      584         lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 8)      584         lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 8)      584         lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 8)      584         lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 32)     0           conv2d_49[0][0]                  \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 8, 8, 32)     0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 64)     2112        re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 64)     2112        re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 64)     256         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 64)     256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 32)     2080        re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 8, 8, 32)     0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 8, 8, 8)      0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 8, 8, 8)      0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 8, 8, 8)      0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 8, 8, 8)      0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 8)      584         lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 8)      584         lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 8)      584         lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 8)      584         lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8, 8, 32)     0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 8, 8, 32)     0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 64)     2112        re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 64)     256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 64)     0           re_lu_27[0][0]                   \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 32)     2080        re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 8, 8, 32)     0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 8, 8, 8)      0           re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 8, 8, 8)      0           re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 8, 8, 8)      0           re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 8, 8, 8)      0           re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 8)      584         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 8)      584         lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 8)      584         lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 8)      584         lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 32)     0           conv2d_62[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 8, 8, 32)     0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 64)     2112        re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 64)     0           re_lu_30[0][0]                   \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 8, 8, 64)     0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 32)     2080        re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 8, 8, 32)     0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 8, 8, 8)      0           re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 8, 8, 8)      0           re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 8, 8, 8)      0           re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 8, 8, 8)      0           re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 8)      584         lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 8)      584         lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 8)      584         lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 8)      584         lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 8, 8, 32)     0           conv2d_68[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 8, 8, 32)     0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 64)     2112        re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 64)     0           re_lu_33[0][0]                   \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 8, 8, 64)     0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 32)     2080        re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, 8, 8, 32)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 8, 8, 8)      0           re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 8, 8, 8)      0           re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 8, 8, 8)      0           re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 8, 8, 8)      0           re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 8)      584         lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 8)      584         lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 8)      584         lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 8)      584         lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 8, 8, 32)     0           conv2d_74[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 8, 8, 32)     0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 64)     2112        re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 64)     0           re_lu_36[0][0]                   \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 8, 8, 64)     0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 32)     2080        re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 8, 8, 32)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 8, 8, 8)      0           re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 8, 8, 8)      0           re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 8, 8, 8)      0           re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 8, 8, 8)      0           re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 8)      584         lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 8)      584         lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 8)      584         lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 8)      584         lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 8, 8, 32)     0           conv2d_80[0][0]                  \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 8, 8, 32)     0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 64)     2112        re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 64)     0           re_lu_39[0][0]                   \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_42 (ReLU)                 (None, 8, 8, 64)     0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 64)     4160        re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_43 (ReLU)                 (None, 8, 8, 64)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 8, 8, 16)     0           re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 8, 8, 16)     0           re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 8, 8, 16)     0           re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 8, 8, 16)     0           re_lu_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 4, 4, 16)     2320        lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 4, 4, 16)     2320        lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 4, 4, 16)     2320        lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 16)     2320        lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 4, 4, 64)     0           conv2d_86[0][0]                  \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_44 (ReLU)                 (None, 4, 4, 64)     0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 64)     4160        re_lu_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 64)     4160        re_lu_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 64)     256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 64)     0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_45 (ReLU)                 (None, 4, 4, 64)     0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 64)     4160        re_lu_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_46 (ReLU)                 (None, 4, 4, 64)     0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 4, 4, 16)     0           re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 4, 4, 16)     0           re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 4, 4, 16)     0           re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 4, 4, 16)     0           re_lu_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 16)     2320        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 16)     2320        lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 16)     2320        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 16)     2320        lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 4, 4, 64)     0           conv2d_93[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_47 (ReLU)                 (None, 4, 4, 64)     0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 64)     4160        re_lu_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 64)     256         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 64)     0           re_lu_45[0][0]                   \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_48 (ReLU)                 (None, 4, 4, 64)     0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 64)     4160        re_lu_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_49 (ReLU)                 (None, 4, 4, 64)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 4, 4, 16)     0           re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 4, 4, 16)     0           re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 4, 4, 16)     0           re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 4, 4, 16)     0           re_lu_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 16)     2320        lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 4, 4, 16)     2320        lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 16)     2320        lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 16)     2320        lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 4, 4, 64)     0           conv2d_99[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_101[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_50 (ReLU)                 (None, 4, 4, 64)     0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 64)     4160        re_lu_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 64)     256         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 64)     0           re_lu_48[0][0]                   \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_51 (ReLU)                 (None, 4, 4, 64)     0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           re_lu_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           1040        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            17          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 145,953\n",
      "Trainable params: 143,969\n",
      "Non-trainable params: 1,984\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31760 samples, validate on 4538 samples\n",
      "Epoch 1/200\n",
      " - 175s - loss: 6.3361 - acc: 0.0924 - val_loss: 16.1152 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      " - 164s - loss: 8.2164 - acc: 0.0060 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      " - 167s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      " - 167s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      " - 167s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      " - 167s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      " - 170s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      " - 169s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      " - 168s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      " - 169s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      " - 173s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 51/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 59/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 60/200\n",
      " - 167s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 77/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      " - 176s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      " - 172s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 101/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 102/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 103/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 104/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 106/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 107/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 108/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 109/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 111/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 112/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 113/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 114/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 115/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 116/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 117/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 118/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 119/200\n",
      " - 168s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 120/200\n",
      " - 168s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 121/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 122/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 123/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 124/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 125/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 126/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 127/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 128/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 129/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 130/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 131/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 132/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 133/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 134/200\n",
      " - 170s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 135/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 136/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 137/200\n",
      " - 171s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 138/200\n",
      " - 169s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 139/200\n",
      " - 167s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 140/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 141/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 142/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 143/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 144/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 145/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 146/200\n",
      " - 168s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 147/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 148/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 149/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 150/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 151/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 152/200\n",
      " - 167s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 153/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 154/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 155/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 156/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 157/200\n",
      " - 166s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 158/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 159/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 160/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 161/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 162/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 163/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 164/200\n",
      " - 171s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 165/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 167/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 168/200\n",
      " - 163s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 169/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 170/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 171/200\n",
      " - 164s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 172/200\n",
      " - 165s - loss: 9.1101 - acc: 0.0000e+00 - val_loss: 1.1921e-07 - val_acc: 0.0000e+00\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-00d4fce9e056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    141\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                       \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m                       batch_size = 64, verbose = 2 )\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[0mPredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rocke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\rocke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rocke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rocke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rocke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Last model: RNN_Test\n",
    "model = load_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-3), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 100, initial_epoch = 25, \n",
    "                      validation_split = (1 / 8), \n",
    "                      batch_size = 64, verbose = 2 )\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "\n",
    "Accuracy = _1vAll_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'ResNet_100e_history'\n",
    "model_str   = 'ResNet_100e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)\n",
    "\n",
    "acc = model_obj.history['acc']\n",
    "val_acc = model_obj.history['val_acc']\n",
    "loss = model_obj.history['loss']\n",
    "val_loss = model_obj.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, acc, 'bd', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Accuracy', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, loss, 'rd', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Loss', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, np.round_(Predictions))\n",
    "cm_plot_labels = ['Not Infiltration', 'Infiltration']\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title = model_str, normalize=True)\n",
    "#save_plt(fig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Infiltration One Vs. All - Nesterov Adam Optimizer\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.005), input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(SpatialDropout2D(0.25))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.005)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.005)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.005)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Last model: 1vAll_Nadam_poisson_100e\n",
    "#model = load_model()\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.Nadam(), \n",
    "              loss = 'poisson', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 100, initial_epoch = 0, \n",
    "                      validation_split = (1 / 8), \n",
    "                      batch_size = 128, verbose = 2 )\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "\n",
    "Accuracy = _1vAll_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = '1vAll_Nadam_poisson_100e_history'\n",
    "model_str   = '1vAll_Nadam_poisson_100e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)\n",
    "\n",
    "acc = model_obj.history['acc']\n",
    "val_acc = model_obj.history['val_acc']\n",
    "loss = model_obj.history['loss']\n",
    "val_loss = model_obj.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, acc, 'bd', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Accuracy', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, loss, 'rd', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Loss', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, np.round_(Predictions))\n",
    "cm_plot_labels = ['Not Infiltration', 'Infiltration']\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title = model_str, normalize=True)\n",
    "#save_plt(fig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Infiltration One Vs. All - Nesterov Adam Optimizer\n",
    "# v2: More filters and Neurons in Dense\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.005), input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(SpatialDropout2D(0.25))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.005)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.005)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.005)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Last model: 1vAll_Nadam_v2_100e\n",
    "#model = load_model()\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 100, initial_epoch = 0, \n",
    "                      validation_split = (1 / 8), \n",
    "                      batch_size = 64, verbose = 1 )\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "\n",
    "Accuracy = _1vAll_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = '1vAll_Nadam_v2_100e_history'\n",
    "model_str   = '1vAll_Nadam_v2_100e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)\n",
    "\n",
    "acc = model_obj.history['acc']\n",
    "val_acc = model_obj.history['val_acc']\n",
    "loss = model_obj.history['loss']\n",
    "val_loss = model_obj.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, acc, 'bd', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Accuracy', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, loss, 'rd', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Loss', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, np.round_(Predictions))\n",
    "cm_plot_labels = ['Not Infiltration', 'Infiltration']\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title = model_str, normalize=True)\n",
    "#save_plt(fig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Infiltration One Vs. All\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005), input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(SpatialDropout2D(0.25))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Last model: Infiltration_1vAll_125e\n",
    "model = load_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-3), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "#model_obj = model.fit(training_img, training_labels, \n",
    "#                      epochs = 150, initial_epoch = 125, \n",
    "#                      validation_split = (1 / 8), \n",
    "#                      batch_size = 64, verbose = 2 )\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "\n",
    "Accuracy = _1vAll_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'Infiltration_1vAll_150e_history'\n",
    "model_str   = 'Infiltration_1vAll_150e'\n",
    "    \n",
    "#save_model(model_obj, history_str, model_str)\n",
    "\n",
    "acc = model_obj.history['acc']\n",
    "val_acc = model_obj.history['val_acc']\n",
    "loss = model_obj.history['loss']\n",
    "val_loss = model_obj.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, acc, 'bd', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Accuracy', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, loss, 'rd', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Loss', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, np.round_(Predictions))\n",
    "cm_plot_labels = ['Not Infiltration', 'Infiltration']\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title = 'Infiltration_1vAll_125e', normalize=True)\n",
    "#save_plt(fig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Infiltration One Vs. All\n",
    "# v2: More layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', \n",
    "                        kernel_regularizer=regularizers.l2(0.005), \n",
    "                        input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(SpatialDropout2D(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(SpatialDropout2D(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Last model: Infiltration_1vAll_v2_100e\n",
    "model = load_model()\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 150, initial_epoch = 100, \n",
    "                      validation_split = (1 / 8), \n",
    "                      batch_size = 64, verbose = 2 )\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "\n",
    "Accuracy = _1vAll_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'Infiltration_1vAll_v2_150e_history'\n",
    "model_str   = 'Infiltration_1vAll_v2_150e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)\n",
    "\n",
    "acc = model_obj.history['acc']\n",
    "val_acc = model_obj.history['val_acc']\n",
    "loss = model_obj.history['loss']\n",
    "val_loss = model_obj.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, acc, 'bd', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Accuracy', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(epochs, loss, 'rd', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss', fontsize='xx-large')\n",
    "plt.xticks(fontsize='xx-large')\n",
    "plt.xlabel('Epochs', fontsize='xx-large')\n",
    "plt.yticks(fontsize='xx-large')\n",
    "plt.ylabel('Loss', fontsize='xx-large')\n",
    "plt.legend(fontsize='xx-large')\n",
    "plt.show()\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, np.round_(Predictions))\n",
    "cm_plot_labels = ['Not Infiltration', 'Infiltration']\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title = model_str, normalize=True)\n",
    "#save_plt(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
