{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold = np.nan, linewidth = 115)\n",
    "import pickle\n",
    "import keras\n",
    "from keras import models, optimizers, layers, regularizers, metrics, losses\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU, ReLU, ThresholdedReLU\n",
    "from keras.layers.core import Dense, Dropout, SpatialDropout2D, Activation\n",
    "from keras.layers.convolutional import Conv2D, SeparableConv2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import model_from_json, Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Save Comparison model\n",
    "def save_model(model_name, hist_str, model_str):\n",
    "\n",
    "    pickle.dump(model_name.history, open('Training Histories/'+ hist_str + '.p', 'wb'))\n",
    "    \n",
    "    print(\"Saved \" + hist_str + \" to Training Histories folder\")\n",
    "    \n",
    "    # serialize model to JSON\n",
    "    model_name = model.to_json()\n",
    "    with open(\"CNN Models/\" + model_str + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_name)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Saved \" + model_str + \" and weights to CNN Models folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with pickle instead of processing images again\n",
    "training_img_1 = pickle.load(open('training_img_resampled_1st_half.p', 'rb'))\n",
    "training_img_2 = pickle.load(open('training_img_resampled_2nd_half.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img = np.append(training_img_1, training_img_2, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = pickle.load(open('pickle_test_img.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_1 = pickle.load(open('training_labels_resampled_1st_half.p', 'rb'))\n",
    "labels_2 = pickle.load(open('training_labels_resampled_2nd_half.p', 'rb'))\n",
    "\n",
    "training_labels = np.append(labels_1, labels_2, axis = 0)\n",
    "\n",
    "test_labels = pickle.load(open('test_labels.p', 'rb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Analysis\n",
    "def true_accuracy(y_test, pred):\n",
    "    \n",
    "    pred = np.round_(pred)\n",
    "    pred = pred.astype(dtype = 'uint8')\n",
    "    \n",
    "    ft = pred == y_test\n",
    "    \n",
    "    acc = []\n",
    "    \n",
    "    counter = 0\n",
    "    while counter < len(ft):\n",
    "        if sum(ft[counter]) < 15:\n",
    "            acc.append(0)\n",
    "            counter += 1\n",
    "        else:\n",
    "            acc.append(1)\n",
    "            counter += 1\n",
    "            \n",
    "    # Accuracy       \n",
    "    Acc = (sum(acc)/len(acc))\n",
    "    \n",
    "    print('\\t Complete Label Accuracy: ', (Acc * 100), '%')\n",
    "    \n",
    "    print('Sum of Fully Correct Predictions: ', sum(acc))\n",
    "    print('\\t\\t    Total Labels: ', len(acc))\n",
    "    \n",
    "    if Acc == 0:\n",
    "        message = 'Feels Devastating (ﾉಥ益ಥ）ﾉ ┻━┻'\n",
    "        \n",
    "    elif Acc > 0 and Acc < 50:\n",
    "        message = 'Feels Awful (੭ ˃̣̣̥ ㅂ˂̣̣̥)੭ु'\n",
    "        \n",
    "    elif Acc >= 50 and Acc < 60:\n",
    "        message = 'Feels Bad (⌯˃̶᷄ ﹏ ˂̶᷄⌯)'\n",
    "        \n",
    "    elif Acc >= 60 and Acc < 70:\n",
    "        message = 'Feels Meh... ┬─┬ノ(ಠ_ಠノ)'\n",
    "    \n",
    "    elif Acc >= 70 and Acc < 80:\n",
    "        message = 'Feels Ok ʕ ·㉨·ʔ'\n",
    "    \n",
    "    elif Acc >= 80 and Acc < 90:\n",
    "        message = 'Feels Better (^._.^)ﾉ'\n",
    "        \n",
    "    elif Acc >= 90 and Acc < 95:\n",
    "        message = 'Feels Hopeful ( •́ ⍨ •̀)'\n",
    "        \n",
    "    elif Acc >= 95 and Acc < 98:\n",
    "        message = 'Feels Good ヽ|･ω･|ゞ'\n",
    "        \n",
    "    elif Acc >= 98:\n",
    "        message = 'Feels Great! ᕙ( * •̀ ᗜ •́ * )ᕗ'\n",
    "        \n",
    "    print('\\n', message)\n",
    "    \n",
    "    return Acc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "og_class_weights = [{0: 1, 1: 9.69980},\n",
    "                 {0: 1, 1: 40.38905},\n",
    "                 {0: 1, 1: 24.02400},\n",
    "                 {0: 1, 1: 48.68432},\n",
    "                 {0: 1, 1: 8.41931},\n",
    "                 {0: 1, 1: 44.56280},\n",
    "                 {0: 1, 1: 66.50059},\n",
    "                 {0: 1, 1: 493.92071},\n",
    "                 {0: 1, 1: 5.63587},\n",
    "                 {0: 1, 1: 19.39121},\n",
    "                 {0: 1, 1: 1.00000},\n",
    "                 {0: 1, 1: 17.70968},\n",
    "                 {0: 1, 1: 33.12260},\n",
    "                 {0: 1, 1: 78.35080},\n",
    "                 {0: 1, 1: 21.14674}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Atelectasis Weight:  29.58311345646438\n",
      "      Cardiomegaly Weight:  115.34979423868313\n",
      "     Consolidation Weight:  94.37710437710437\n",
      "             Edema Weight:  190.68027210884352\n",
      "          Effusion Weight:  30.998064694498204\n",
      "         Emphysema Weight:  143.19284802043424\n",
      "          Fibrosis Weight:  202.018018018018\n",
      "            Hernia Weight:  1274.090909090909\n",
      "      Infiltration Weight:  12.9379183014078\n",
      "              Mass Weight:  55.94810379241517\n",
      "        No_Finding Weight:  2.079723989538313\n",
      "            Nodule Weight:  45.24616626311541\n",
      "Pleural_Thickening Weight:  114.05900305188199\n",
      "         Pneumonia Weight:  396.18374558303884\n",
      "      Pneumothorax Weight:  57.73429454170958\n"
     ]
    }
   ],
   "source": [
    "Atelectasis        = 112120 / 3790\n",
    "Cardiomegaly       = 112120 / 972\n",
    "Consolidation      = 112120 / 1188\n",
    "Edema              = 112120 / 588\n",
    "Effusion           = 112120 / 3617\n",
    "Emphysema          = 112120 / 783\n",
    "Fibrosis           = 112120 / 555\n",
    "Hernia             = 112120 / 88\n",
    "Infiltration       = 112120 / 8666\n",
    "Mass               = 112120 / 2004\n",
    "No_Finding         = 112120 / 53911\n",
    "Nodule             = 112120 / 2478\n",
    "Pleural_Thickening = 112120 / 983\n",
    "Pneumonia          = 112120 / 283\n",
    "Pneumothorax       = 112120 / 1942\n",
    "\n",
    "print('       Atelectasis Weight: ', Atelectasis)       \n",
    "print('      Cardiomegaly Weight: ', Cardiomegaly)      \n",
    "print('     Consolidation Weight: ', Consolidation)     \n",
    "print('             Edema Weight: ', Edema)             \n",
    "print('          Effusion Weight: ', Effusion)          \n",
    "print('         Emphysema Weight: ', Emphysema)         \n",
    "print('          Fibrosis Weight: ', Fibrosis)          \n",
    "print('            Hernia Weight: ', Hernia)            \n",
    "print('      Infiltration Weight: ', Infiltration)      \n",
    "print('              Mass Weight: ', Mass)              \n",
    "print('        No_Finding Weight: ', No_Finding)        \n",
    "print('            Nodule Weight: ', Nodule)            \n",
    "print('Pleural_Thickening Weight: ', Pleural_Thickening)\n",
    "print('         Pneumonia Weight: ', Pneumonia)         \n",
    "print('      Pneumothorax Weight: ', Pneumothorax)\n",
    "\n",
    "yung_class_weights = [{0: 1, 1: Atelectasis},\n",
    "                      {0: 1, 1: Cardiomegaly},\n",
    "                      {0: 1, 1: Consolidation},\n",
    "                      {0: 1, 1: Edema},\n",
    "                      {0: 1, 1: Effusion},\n",
    "                      {0: 1, 1: Emphysema},\n",
    "                      {0: 1, 1: Fibrosis},\n",
    "                      {0: 1, 1: Hernia},\n",
    "                      {0: 1, 1: Infiltration},\n",
    "                      {0: 1, 1: Mass},\n",
    "                      {0: 1, 1: No_Finding},\n",
    "                      {0: 1, 1: Nodule},\n",
    "                      {0: 1, 1: Pleural_Thickening},\n",
    "                      {0: 1, 1: Pneumonia},\n",
    "                      {0: 1, 1: Pneumothorax}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_weights = [{0:1., 1: 94.086},\n",
    "              {0:1., 1: 1631.2754},\n",
    "              {0:1., 1: 577.1525},\n",
    "              {0:1., 1: 2370.163},\n",
    "              {0:1., 1: 70.8848},\n",
    "              {0:1., 1: 1985.8431},\n",
    "              {0:1., 1: 4422.3285},\n",
    "              {0:1., 1: 243957.6678},\n",
    "              {0:1., 1: 31.76303},\n",
    "              {0:1., 1: 376.019025},\n",
    "              {0:1., 1: 1.},\n",
    "              {0:1., 1: 313.63277},\n",
    "              {0:1., 1: 1097.106631},\n",
    "              {0:1., 1: 6138.84786},\n",
    "              {0:1., 1: 447.1846}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57775 samples, validate on 7222 samples\n",
      "Epoch 1/20\n",
      "57775/57775 [==============================] - 106s 2ms/step - loss: 0.3010 - categorical_accuracy: 0.2537 - val_loss: 0.4921 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "57775/57775 [==============================] - 101s 2ms/step - loss: 0.2620 - categorical_accuracy: 0.3053 - val_loss: 0.4252 - val_categorical_accuracy: 8.3079e-04\n",
      "Epoch 3/20\n",
      "57775/57775 [==============================] - 101s 2ms/step - loss: 0.2544 - categorical_accuracy: 0.3189 - val_loss: 0.4456 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "57775/57775 [==============================] - 105s 2ms/step - loss: 0.2504 - categorical_accuracy: 0.3259 - val_loss: 0.4403 - val_categorical_accuracy: 0.0011\n",
      "Epoch 5/20\n",
      "57775/57775 [==============================] - 109s 2ms/step - loss: 0.2475 - categorical_accuracy: 0.3323 - val_loss: 0.4212 - val_categorical_accuracy: 2.7693e-04\n",
      "Epoch 6/20\n",
      "57775/57775 [==============================] - 111s 2ms/step - loss: 0.2454 - categorical_accuracy: 0.3376 - val_loss: 0.4213 - val_categorical_accuracy: 0.0014\n",
      "Epoch 7/20\n",
      "57775/57775 [==============================] - 116s 2ms/step - loss: 0.2435 - categorical_accuracy: 0.3412 - val_loss: 0.4231 - val_categorical_accuracy: 0.0014\n",
      "Epoch 8/20\n",
      "57775/57775 [==============================] - 110s 2ms/step - loss: 0.2419 - categorical_accuracy: 0.3457 - val_loss: 0.4013 - val_categorical_accuracy: 0.0144\n",
      "Epoch 9/20\n",
      "57775/57775 [==============================] - 117s 2ms/step - loss: 0.2400 - categorical_accuracy: 0.3481 - val_loss: 0.3917 - val_categorical_accuracy: 0.0450\n",
      "Epoch 10/20\n",
      "57775/57775 [==============================] - 110s 2ms/step - loss: 0.2382 - categorical_accuracy: 0.3522 - val_loss: 0.4439 - val_categorical_accuracy: 0.0014\n",
      "Epoch 11/20\n",
      "57775/57775 [==============================] - 113s 2ms/step - loss: 0.2364 - categorical_accuracy: 0.3569 - val_loss: 0.4165 - val_categorical_accuracy: 0.0051\n",
      "Epoch 12/20\n",
      "57775/57775 [==============================] - 117s 2ms/step - loss: 0.2346 - categorical_accuracy: 0.3596 - val_loss: 0.4303 - val_categorical_accuracy: 0.0028\n",
      "Epoch 13/20\n",
      "57775/57775 [==============================] - 114s 2ms/step - loss: 0.2329 - categorical_accuracy: 0.3648 - val_loss: 0.4175 - val_categorical_accuracy: 0.0148\n",
      "Epoch 14/20\n",
      "57775/57775 [==============================] - 116s 2ms/step - loss: 0.2311 - categorical_accuracy: 0.3691 - val_loss: 0.4241 - val_categorical_accuracy: 0.0064\n",
      "Epoch 15/20\n",
      "57775/57775 [==============================] - 115s 2ms/step - loss: 0.2293 - categorical_accuracy: 0.3718 - val_loss: 0.4094 - val_categorical_accuracy: 0.0331\n",
      "Epoch 16/20\n",
      "57775/57775 [==============================] - 104s 2ms/step - loss: 0.2276 - categorical_accuracy: 0.3765 - val_loss: 0.4109 - val_categorical_accuracy: 0.0138\n",
      "Epoch 17/20\n",
      "57775/57775 [==============================] - 101s 2ms/step - loss: 0.2258 - categorical_accuracy: 0.3822 - val_loss: 0.4307 - val_categorical_accuracy: 0.0090\n",
      "Epoch 18/20\n",
      "57775/57775 [==============================] - 101s 2ms/step - loss: 0.2240 - categorical_accuracy: 0.3870 - val_loss: 0.4003 - val_categorical_accuracy: 0.0417\n",
      "Epoch 19/20\n",
      "57775/57775 [==============================] - 101s 2ms/step - loss: 0.2221 - categorical_accuracy: 0.3905 - val_loss: 0.4164 - val_categorical_accuracy: 0.0258\n",
      "Epoch 20/20\n",
      "57775/57775 [==============================] - 101s 2ms/step - loss: 0.2203 - categorical_accuracy: 0.3968 - val_loss: 0.4319 - val_categorical_accuracy: 0.0126\n",
      "\t Complete Label Accuracy:  13.646093471280771 %\n",
      "Sum of Fully Correct Predictions:  1530\n",
      "\t\t    Total Labels:  11212\n",
      "\n",
      " Feels Awful (੭ ˃̣̣̥ ㅂ˂̣̣̥)੭ु\n",
      "Saved baseline_v7_20e_history to Training Histories folder\n",
      "Saved baseline_v7_20e and weights to CNN Models folder\n"
     ]
    }
   ],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "# v3: Class Weights squared\n",
    "# v4: Resampled data\n",
    "# v5: No weights\n",
    "# v6: Using OG Class Weights\n",
    "# v7: Random Under Sample Data and using yung_class_weights\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=yung_class_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v7_20e_history'\n",
    "model_str   = 'baseline_v7_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseline Model for reference\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 128, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_30_history'\n",
    "model_str   = 'baseline_30'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=og_class_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v2_20e_history'\n",
    "model_str   = 'baseline_v2_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "# v3: Class Weights squared\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=exp_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v3_20e_history'\n",
    "model_str   = 'baseline_v3_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "# v3: Class Weights squared\n",
    "# v4: Resampled data\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=exp_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v4_20e_history'\n",
    "model_str   = 'baseline_v4_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes Weighted based on presence in data\n",
    "# v3: Class weights squared\n",
    "# v4: Resampled data\n",
    "# v5: No weights\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v5_20e_history'\n",
    "model_str   = 'baseline_v5_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Classes weighted based on presence in data\n",
    "# v3: Class Weights squared\n",
    "# v4: Resampled data\n",
    "# v5: No weights\n",
    "# v6: Using OG Class Weights\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-5), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 128, verbose = 1, class_weight=og_class_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'baseline_v6_20e_history'\n",
    "model_str   = 'baseline_v6_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "# v4: Added Batch Normalization to all layers\n",
    "# v5: Using softmax final activation\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 4\n",
    "#model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.375))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = (1 / 9), batch_size = 256, verbose = 1, class_weight=class_weights)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v5_20e_history'\n",
    "model_str   = 'vanilla_reg_VGG_v5_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG_Doppleganger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly taken from VGG16 with 2D Spatial Dropout, Dropout, and fewer Dense layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 30, validation_split = (1/9), \n",
    "                      batch_size = 128, verbose = 1)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_history'\n",
    "model_str   = 'VGG_Doppleganger_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = 0.1, batch_size = 128, verbose = 1)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_v3_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "# v3: Using Categorical Accuracy as metrics\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = 0.1, batch_size = 128)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_v3_history'\n",
    "model_str   = 'VGG_Doppleganger_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla_VGG_Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on VGG with half reg'd layers and Dropout layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v2_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v2_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v3_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v4_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v5_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v5_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "# v6: Added Batch Normalization layers to each Block\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1, class_weight= class_weights )\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v6_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v6_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = model.predict(test_img)\n",
    "print(Predictions)\n",
    "#Accuracy = true_accuracy(test_labels, Predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla_reg_VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeled after VGGNet with half reg'd layers\n",
    "vanilla_reg_VGG = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_reg_VGG.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "vanilla_reg_VGG.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "vanilla_reg_VGG.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "vanilla_reg_VGG.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "vanilla_reg_VGG.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "vanilla_reg_VGG.add(layers.Flatten())\n",
    "vanilla_reg_VGG.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "vanilla_reg_VGG.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = vanilla_reg_VGG.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_history'\n",
    "model_str   = 'vanilla_reg_VGG_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v2_history'\n",
    "model_str   = 'vanilla_reg_VGG_v2_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v3_history'\n",
    "model_str   = 'vanilla_reg_VGG_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "# v4: Added Batch Normalization to all layers\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "'''\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Predictions = Predictions.astype(dtype = 'int32')\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v4_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(SeparableConv2D(8, (3, 3), \n",
    "                          kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation = 'elu', \n",
    "                          input_shape = (256, 256, 1)))\n",
    "model.add(SeparableConv2D(8, (3, 3), \n",
    "                          kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation = 'elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), \n",
    "                 kernel_regularizer=regularizers.l2(0.001),\n",
    "                 activation = 'elu'))\n",
    "model.add(Conv2D(32, (3, 3), \n",
    "                 kernel_regularizer=regularizers.l2(0.001),\n",
    "                 activation = 'elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(64, activation = 'elu'))\n",
    "model.add(Dense(15, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-3), \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 20, validation_split = (1/9), \n",
    "                      batch_size = 128, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Predictions = Predictions.astype(dtype = 'int32')\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v4_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
