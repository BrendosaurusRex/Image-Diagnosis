{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold = np.nan, linewidth = 115)\n",
    "import pickle\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import models, optimizers, layers, regularizers, metrics, losses\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU, ELU, ReLU, ThresholdedReLU\n",
    "from keras.layers.core import Dense, Dropout, SpatialDropout2D, Activation\n",
    "from keras.layers.convolutional import Conv2D, SeparableConv2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import model_from_json, Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Save Comparison model\n",
    "def save_model(model_name, hist_str, model_str):\n",
    "\n",
    "    pickle.dump(model_name.history, open('Training Histories/'+ hist_str + '.p', 'wb'))\n",
    "    \n",
    "    print(\"Saved \" + hist_str + \" to Training Histories folder\")\n",
    "    \n",
    "    # serialize model to JSON\n",
    "    model_name = model.to_json()\n",
    "    with open(\"CNN Models/\" + model_str + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_name)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Saved \" + model_str + \" and weights to CNN Models folder\")\n",
    "\n",
    "# Load with pickle instead of processing images again\n",
    "training_img_1 = pickle.load(open('training_img_1.p', 'rb'))\n",
    "training_img_2 = pickle.load(open('training_img_2.p', 'rb'))\n",
    "training_img = np.append(training_img_1, training_img_2, axis = 0)\n",
    "\n",
    "test_img = pickle.load(open('pickle_test_img.p', 'rb'))\n",
    "\n",
    "training_labels = pickle.load(open('training_labels.p', 'rb'))\n",
    "test_labels = pickle.load(open('test_labels.p', 'rb'))    \n",
    "\n",
    "# Metric Analysis\n",
    "def true_accuracy(y_test, pred):\n",
    "    \n",
    "    pred = pred.astype(dtype = 'int32')\n",
    "    \n",
    "    ft = pred == y_test\n",
    "    \n",
    "    acc = []\n",
    "    \n",
    "    counter = 0\n",
    "    while counter < len(ft):\n",
    "        if sum(ft[counter]) < 15:\n",
    "            acc.append(0)\n",
    "            counter += 1\n",
    "        else:\n",
    "            acc.append(1)\n",
    "            counter += 1\n",
    "            \n",
    "    # Accuracy       \n",
    "    Acc = (sum(acc)/len(acc))\n",
    "    \n",
    "    print('\\t Complete Label Accuracy: ', (Acc * 100), '%')\n",
    "    \n",
    "    print('Sum of Fully Correct Predictions: ', sum(acc))\n",
    "    print('\\t\\t    Total Labels: ', len(acc))\n",
    "    \n",
    "    if Acc == 0:\n",
    "        message = 'Feels Devastating (ﾉಥ益ಥ）ﾉ ┻━┻'\n",
    "        \n",
    "    elif Acc > 0 and Acc < 50:\n",
    "        message = 'Feels Awful (੭ ˃̣̣̥ ㅂ˂̣̣̥)੭ु'\n",
    "        \n",
    "    elif Acc >= 50 and Acc < 60:\n",
    "        message = 'Feels Bad (⌯˃̶᷄ ﹏ ˂̶᷄⌯)'\n",
    "        \n",
    "    elif Acc >= 60 and Acc < 70:\n",
    "        message = 'Feels Meh... ┬─┬ノ(ಠ_ಠノ)'\n",
    "    \n",
    "    elif Acc >= 70 and Acc < 80:\n",
    "        message = 'Feels Ok ʕ ·㉨·ʔ'\n",
    "    \n",
    "    elif Acc >= 80 and Acc < 90:\n",
    "        message = 'Feels Better (^._.^)ﾉ'\n",
    "        \n",
    "    elif Acc >= 90 and Acc < 95:\n",
    "        message = 'Feels Hopeful ( •́ ⍨ •̀)'\n",
    "        \n",
    "    elif Acc >= 95 and Acc < 98:\n",
    "        message = 'Feels Good ヽ|･ω･|ゞ'\n",
    "        \n",
    "    elif Acc >= 98:\n",
    "        message = 'Feels Great! ᕙ( * •̀ ᗜ •́ * )ᕗ'\n",
    "        \n",
    "    print('\\n', message)\n",
    "    \n",
    "    return Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-174182ee15b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n\u001b[0;32m     45\u001b[0m               \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m               metrics = ['categorical_accuracy'])\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mmodel_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rocke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[1;32m--> 332\u001b[1;33m                                                 sample_weight, mask)\n\u001b[0m\u001b[0;32m    333\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rocke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    401\u001b[0m         \"\"\"\n\u001b[0;32m    402\u001b[0m         \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-127fd5f1abdf>\u001b[0m in \u001b[0;36mtf_accuracy\u001b[1;34m(y_test, pred)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    }
   ],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "# v4: Added Batch Normalization to all layers\n",
    "# v5: Using softmax final activation\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.375))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = tf_accuracy, \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 10, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Predictions = Predictions.astype(dtype = 'int32')\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "print('\\t Complete Label Accuracy: ', (Accuracy * 100), '%')\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v5_history'\n",
    "model_str   = 'vanilla_reg_VGG_v5_20e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Analysis\n",
    "def tf_accuracy(y_test, pred):\n",
    "    \n",
    "    int_pred = tf.cast(pred, tf.int32)\n",
    "    \n",
    "    ft = int_pred == y_test\n",
    "    \n",
    "    acc = []\n",
    "    \n",
    "    counter = 0\n",
    "    while counter < len(ft):\n",
    "        if sum(ft[counter]) < 15:\n",
    "            acc.append(0)\n",
    "            counter += 1\n",
    "        else:\n",
    "            acc.append(1)\n",
    "            counter += 1\n",
    "            \n",
    "    # Accuracy       \n",
    "    Acc = (sum(acc)/len(acc))\n",
    "    \n",
    "    #print('\\t Complete Label Accuracy: ', (Acc * 100), '%')\n",
    "    \n",
    "    #print('Sum of Fully Correct Predictions: ', sum(acc))\n",
    "    #print('\\t\\t    Total Labels: ', len(acc))\n",
    "    \n",
    "    if Acc == 0:\n",
    "        message = 'Feels Devastating (ﾉಥ益ಥ）ﾉ ┻━┻'\n",
    "        \n",
    "    elif Acc > 0 and Acc < 50:\n",
    "        message = 'Feels Awful (੭ ˃̣̣̥ ㅂ˂̣̣̥)੭ु'\n",
    "        \n",
    "    elif Acc >= 50 and Acc < 60:\n",
    "        message = 'Feels Bad (⌯˃̶᷄ ﹏ ˂̶᷄⌯)'\n",
    "        \n",
    "    elif Acc >= 60 and Acc < 70:\n",
    "        message = 'Feels Meh... ┬─┬ノ(ಠ_ಠノ)'\n",
    "    \n",
    "    elif Acc >= 70 and Acc < 80:\n",
    "        message = 'Feels Ok ʕ ·㉨·ʔ'\n",
    "    \n",
    "    elif Acc >= 80 and Acc < 90:\n",
    "        message = 'Feels Better (^._.^)ﾉ'\n",
    "        \n",
    "    elif Acc >= 90 and Acc < 95:\n",
    "        message = 'Feels Hopeful ( •́ ⍨ •̀)'\n",
    "        \n",
    "    elif Acc >= 95 and Acc < 98:\n",
    "        message = 'Feels Good ヽ|･ω･|ゞ'\n",
    "        \n",
    "    elif Acc >= 98:\n",
    "        message = 'Feels Great! ᕙ( * •̀ ᗜ •́ * )ᕗ'\n",
    "        \n",
    "    print('\\n', message)\n",
    "    \n",
    "    return K.mean(Acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG_Doppleganger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly taken from VGG16 with 2D Spatial Dropout, Dropout, and fewer Dense layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 30, validation_split = (1/9), \n",
    "                      batch_size = 128, verbose = 1)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_history'\n",
    "model_str   = 'VGG_Doppleganger_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = 0.1, batch_size = 128, verbose = 1)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_v3_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "# v3: Using Categorical Accuracy as metrics\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = 0.1, batch_size = 128)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_v3_history'\n",
    "model_str   = 'VGG_Doppleganger_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla_VGG_Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on VGG with half reg'd layers and Dropout layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v2_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v2_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v3_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v4_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v5_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v5_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "# v6: Added Batch Normalization layers to each Block\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v6_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v6_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla_reg_VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeled after VGGNet with half reg'd layers\n",
    "vanilla_reg_VGG = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_reg_VGG.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "vanilla_reg_VGG.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "vanilla_reg_VGG.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "vanilla_reg_VGG.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "vanilla_reg_VGG.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "vanilla_reg_VGG.add(layers.Flatten())\n",
    "vanilla_reg_VGG.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "vanilla_reg_VGG.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = vanilla_reg_VGG.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_history'\n",
    "model_str   = 'vanilla_reg_VGG_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v2_history'\n",
    "model_str   = 'vanilla_reg_VGG_v2_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v3_history'\n",
    "model_str   = 'vanilla_reg_VGG_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89696 samples, validate on 11212 samples\n",
      "Epoch 1/30\n",
      "89696/89696 [==============================] - 231s 3ms/step - loss: 0.7774 - categorical_accuracy: 0.5222 - val_loss: 0.6684 - val_categorical_accuracy: 0.4410\n",
      "Epoch 2/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.5640 - categorical_accuracy: 0.5307 - val_loss: 0.5251 - val_categorical_accuracy: 0.3634\n",
      "Epoch 3/30\n",
      "89696/89696 [==============================] - 215s 2ms/step - loss: 0.4439 - categorical_accuracy: 0.5344 - val_loss: 0.4228 - val_categorical_accuracy: 0.5078\n",
      "Epoch 4/30\n",
      "89696/89696 [==============================] - 213s 2ms/step - loss: 0.3741 - categorical_accuracy: 0.5373 - val_loss: 0.3744 - val_categorical_accuracy: 0.4585\n",
      "Epoch 5/30\n",
      "89696/89696 [==============================] - 213s 2ms/step - loss: 0.3309 - categorical_accuracy: 0.5421 - val_loss: 0.3405 - val_categorical_accuracy: 0.4790\n",
      "Epoch 6/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.3026 - categorical_accuracy: 0.5460 - val_loss: 0.3209 - val_categorical_accuracy: 0.4988\n",
      "Epoch 7/30\n",
      "89696/89696 [==============================] - 215s 2ms/step - loss: 0.2821 - categorical_accuracy: 0.5524 - val_loss: 0.3004 - val_categorical_accuracy: 0.4897\n",
      "Epoch 8/30\n",
      "89696/89696 [==============================] - 213s 2ms/step - loss: 0.2670 - categorical_accuracy: 0.5592 - val_loss: 0.2959 - val_categorical_accuracy: 0.5052\n",
      "Epoch 9/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.2547 - categorical_accuracy: 0.5687 - val_loss: 0.2847 - val_categorical_accuracy: 0.4782\n",
      "Epoch 10/30\n",
      "89696/89696 [==============================] - 215s 2ms/step - loss: 0.2444 - categorical_accuracy: 0.5773 - val_loss: 0.3109 - val_categorical_accuracy: 0.3520\n",
      "Epoch 11/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.2349 - categorical_accuracy: 0.5877 - val_loss: 0.2867 - val_categorical_accuracy: 0.4692\n",
      "Epoch 12/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.2262 - categorical_accuracy: 0.6007 - val_loss: 0.2804 - val_categorical_accuracy: 0.4946\n",
      "Epoch 13/30\n",
      "89696/89696 [==============================] - 219s 2ms/step - loss: 0.2179 - categorical_accuracy: 0.6167 - val_loss: 0.2810 - val_categorical_accuracy: 0.4829\n",
      "Epoch 14/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.2095 - categorical_accuracy: 0.6345 - val_loss: 0.2899 - val_categorical_accuracy: 0.4288\n",
      "Epoch 15/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.2014 - categorical_accuracy: 0.6529 - val_loss: 0.3130 - val_categorical_accuracy: 0.4996\n",
      "Epoch 16/30\n",
      "89696/89696 [==============================] - 215s 2ms/step - loss: 0.1936 - categorical_accuracy: 0.6679 - val_loss: 0.2952 - val_categorical_accuracy: 0.4347\n",
      "Epoch 17/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.1860 - categorical_accuracy: 0.6892 - val_loss: 0.3140 - val_categorical_accuracy: 0.4859\n",
      "Epoch 18/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.1786 - categorical_accuracy: 0.7066 - val_loss: 0.3180 - val_categorical_accuracy: 0.4495\n",
      "Epoch 19/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.1717 - categorical_accuracy: 0.7214 - val_loss: 0.3199 - val_categorical_accuracy: 0.3851\n",
      "Epoch 20/30\n",
      "89696/89696 [==============================] - 214s 2ms/step - loss: 0.1649 - categorical_accuracy: 0.7421 - val_loss: 0.3288 - val_categorical_accuracy: 0.4185\n",
      "Epoch 21/30\n",
      "89696/89696 [==============================] - 217s 2ms/step - loss: 0.1589 - categorical_accuracy: 0.7548 - val_loss: 0.3469 - val_categorical_accuracy: 0.3699\n",
      "Epoch 22/30\n",
      "89696/89696 [==============================] - 219s 2ms/step - loss: 0.1536 - categorical_accuracy: 0.7678 - val_loss: 0.3469 - val_categorical_accuracy: 0.4511\n",
      "Epoch 23/30\n",
      "89696/89696 [==============================] - 221s 2ms/step - loss: 0.1487 - categorical_accuracy: 0.7802 - val_loss: 0.3637 - val_categorical_accuracy: 0.4348\n",
      "Epoch 24/30\n",
      "89696/89696 [==============================] - 220s 2ms/step - loss: 0.1445 - categorical_accuracy: 0.7887 - val_loss: 0.3638 - val_categorical_accuracy: 0.4467\n",
      "Epoch 25/30\n",
      "89696/89696 [==============================] - 218s 2ms/step - loss: 0.1400 - categorical_accuracy: 0.8000 - val_loss: 0.3825 - val_categorical_accuracy: 0.3854\n",
      "Epoch 26/30\n",
      "89696/89696 [==============================] - 217s 2ms/step - loss: 0.1366 - categorical_accuracy: 0.8063 - val_loss: 0.3882 - val_categorical_accuracy: 0.4122\n",
      "Epoch 27/30\n",
      "89696/89696 [==============================] - 219s 2ms/step - loss: 0.1329 - categorical_accuracy: 0.8158 - val_loss: 0.4129 - val_categorical_accuracy: 0.3548\n",
      "Epoch 28/30\n",
      "89696/89696 [==============================] - 221s 2ms/step - loss: 0.1302 - categorical_accuracy: 0.8205 - val_loss: 0.4373 - val_categorical_accuracy: 0.4584\n",
      "Epoch 29/30\n",
      "89696/89696 [==============================] - 216s 2ms/step - loss: 0.1270 - categorical_accuracy: 0.8280 - val_loss: 0.4186 - val_categorical_accuracy: 0.3636\n",
      "Epoch 30/30\n",
      "89696/89696 [==============================] - 216s 2ms/step - loss: 0.1245 - categorical_accuracy: 0.8314 - val_loss: 0.4578 - val_categorical_accuracy: 0.4087\n",
      "\t Complete Label Accuracy:  0.0 %\n",
      "Sum of Fully Correct Predictions:  0\n",
      "\t\t    Total Labels:  11212\n",
      "\n",
      " Feels Devastating (ﾉಥ益ಥ）ﾉ ┻━┻\n",
      "Saved vanilla_reg_VGG_v4_history to Training Histories folder\n",
      "Saved vanilla_reg_VGG_v4_30e and weights to CNN Models folder\n"
     ]
    }
   ],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "# v4: Added Batch Normalization to all layers\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "'''\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Predictions = Predictions.astype(dtype = 'int32')\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v4_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
