{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Data to Test and Train Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy\n",
    "\n",
    "#train_imagename = open(\"train_val_list.txt\", \"r\")\n",
    "#test_imagename = open(\"test_list.txt\", \"r\")\n",
    "\n",
    "#Reading the textfile and getting a list of string\n",
    "#train_data = train_imagename.readlines()\n",
    "#test_data = test_imagename.readlines()\n",
    "#cnt1 = 0\n",
    "#cnt2 = 0\n",
    "#Taking out the \\n character in the string\n",
    "#for char1 in train_data:\n",
    "#    train_data[cnt1] = char1.rstrip(\"\\n\")\n",
    "#    cnt1 += 1\n",
    "#for char2 in test_data:\n",
    "#    test_data[cnt2] = char2.rstrip(\"\\n\")\n",
    "#    cnt2 += 1\n",
    "#print(train_data)\n",
    "#print(test_data)\n",
    "\n",
    "#import csv\n",
    "\n",
    "#labels_list = []\n",
    "#images = []\n",
    "\n",
    "#with open('Data_Entry_2017.csv') as csvfile:\n",
    "#    readData = csv.reader(csvfile, delimiter = ',')   \n",
    "#    for row in readData:\n",
    "#        label = row[0:2]\n",
    "#        labels_list.append(label)\n",
    "#        images.append(img)\n",
    "        \n",
    "#labels_list = labels_list[1:11]\n",
    "#images = images[1:]\n",
    "#labels = [items.split('|') for items in labels_list]\n",
    "#print(labels_list)\n",
    "#print(images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Transporting repsepctive pictures to folder\n",
    "#path = \"images\"\n",
    "#dest1 = \"test_images\"\n",
    "#dest2 = \"train_images\"\n",
    "\n",
    "#for subdir, dirs, files in os.walk(path):\n",
    "#    for filename in files:\n",
    "#        filepath = subdir + os.sep + filename\n",
    "#        if filename in test_data:\n",
    "#            copy(filepath, dest1)\n",
    "#            print(filepath)\n",
    "#        elif filename in train_data:\n",
    "#            copy(filepath, dest2)\n",
    "#            print(filepath)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Take the first 100 images from the first zip file and put them in a test folder\n",
    "#Put the rest of the images in a training folder\n",
    "TRAIN_DIR = 'C:\\\\Users\\\\julio\\\\URE18\\\\Image_Processing\\\\train_images'\n",
    "TEST_DIR = 'C:\\\\Users\\\\julio\\\\URE18\\\\Image_Processing\\\\test_images'\n",
    "TRAIN_LABEL_DIR = 'Data_Entry_2017.csv'\n",
    "TEST_LABEL_DIR = 'Data_Entry_2017.csv'\n",
    "IMG_SIZE = 256\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "read_data = pd.read_csv(TRAIN_LABEL_DIR)\n",
    "split_labels = [items.split('|')[0] for items in read_data.Finding_Labels]\n",
    "one_hot = MultiLabelBinarizer()\n",
    "training_labels = one_hot.fit_transform(split_labels)\n",
    "training_labels = training_labels[3001:35000]\n",
    "\n",
    "read_data = pd.read_csv(TEST_LABEL_DIR)\n",
    "split_labels = [items.split('|')[0] for items in read_data.Finding_Labels]\n",
    "one_hot = MultiLabelBinarizer()\n",
    "test_labels = one_hot.fit_transform(split_labels)\n",
    "test_labels = test_labels[:3000]\n",
    "\n",
    "def create_batch(directory):\n",
    "    img_array = []\n",
    "    for img in tqdm(os.listdir(directory)):\n",
    "        path = os.path.join(directory, img)\n",
    "        img = tf.image.decode_png(path, channels = 1)\n",
    "        img = tf.image.resize_images(img, [IMG_SIZE, IMG_SIZE])\n",
    "        img_array.append(img)\n",
    "    return img_array\n",
    "\n",
    "training_img = create_batch(TRAIN_DIR)\n",
    "training_img = np.array(training_img)\n",
    "\n",
    "test_img = create_batch(TEST_DIR)\n",
    "test_img = np.array(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#Building the network\n",
    "models = models.Sequential()\n",
    "models.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (256, 256, 1))) #Input layer\n",
    "models.add(layers.MaxPooling2D((2,2)))\n",
    "models.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "models.add(layers.MaxPooling2D((2,2)))\n",
    "models.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "models.add(layers.MaxPooling2D((2,2)))\n",
    "models.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "models.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "models.add(layers.Flatten())\n",
    "models.add(layers.Dense(512, activation = 'relu'))\n",
    "models.add(layers.Dense(15, activation = 'softmax'))\n",
    "\n",
    "#Configuring the model for training\n",
    "from keras import optimizers\n",
    "\n",
    "lr = 1e-4 #learning rate\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr))\n",
    "\n",
    "#Training the model\n",
    "model.fit(training_img, training_label, epochs = 1, batch_size = 128)\n",
    "\n",
    "#models.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "URE18",
   "language": "python",
   "name": "ure18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
