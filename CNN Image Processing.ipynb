{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating Data to Test and Train Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy\n",
    "\n",
    "#train_imagename = open(\"train_val_list.txt\", \"r\")\n",
    "#test_imagename = open(\"test_list.txt\", \"r\")\n",
    "\n",
    "#Reading the textfile and getting a list of string\n",
    "#train_data = train_imagename.readlines()\n",
    "#test_data = test_imagename.readlines()\n",
    "#cnt1 = 0\n",
    "#cnt2 = 0\n",
    "#Taking out the \\n character in the string\n",
    "#for char1 in train_data:\n",
    "#    train_data[cnt1] = char1.rstrip(\"\\n\")\n",
    "#    cnt1 += 1\n",
    "#for char2 in test_data:\n",
    "#    test_data[cnt2] = char2.rstrip(\"\\n\")\n",
    "#    cnt2 += 1\n",
    "#print(train_data)\n",
    "#print(test_data)\n",
    "\n",
    "#import csv\n",
    "\n",
    "#labels_list = []\n",
    "#images = []\n",
    "\n",
    "#with open('Data_Entry_2017.csv') as csvfile:\n",
    "#    readData = csv.reader(csvfile, delimiter = ',')   \n",
    "#    for row in readData:\n",
    "#        label = row[0:2]\n",
    "#        labels_list.append(label)\n",
    "#        images.append(img)\n",
    "        \n",
    "#labels_list = labels_list[1:11]\n",
    "#images = images[1:]\n",
    "#labels = [items.split('|') for items in labels_list]\n",
    "#print(labels_list)\n",
    "#print(images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Transporting repsepctive pictures to folder\n",
    "#path = \"images\"\n",
    "#dest1 = \"test_images\"\n",
    "#dest2 = \"train_images\"\n",
    "\n",
    "#for subdir, dirs, files in os.walk(path):\n",
    "#    for filename in files:\n",
    "#        filepath = subdir + os.sep + filename\n",
    "#        if filename in test_data:\n",
    "#            copy(filepath, dest1)\n",
    "#            print(filepath)\n",
    "#        elif filename in train_data:\n",
    "#            copy(filepath, dest2)\n",
    "#            print(filepath)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Finding_Labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-feec9889bd4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mread_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_LABEL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msplit_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFinding_Labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ellis_venv/my_env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Finding_Labels'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Take the first 100 images from the first zip file and put them in a test folder\n",
    "#Put the rest of the images in a training folder\n",
    "TRAIN_DIR = 'C:\\\\Users\\\\julio\\\\URE18\\\\Image_Processing\\\\train_images'\n",
    "TEST_DIR = 'C:\\\\Users\\\\julio\\\\URE18\\\\Image_Processing\\\\test_images'\n",
    "TRAIN_LABEL_DIR = 'Data_Entry_2017.csv'\n",
    "TEST_LABEL_DIR = 'Data_Entry_2017.csv'\n",
    "IMG_SIZE = 256\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "read_data = pd.read_csv(TRAIN_LABEL_DIR)\n",
    "split_labels = [items.split('|')[0] for items in read_data.Finding_Labels]\n",
    "one_hot = MultiLabelBinarizer()\n",
    "training_labels = one_hot.fit_transform(split_labels)\n",
    "training_labels = training_labels[3001:35000]\n",
    "\n",
    "read_data = pd.read_csv(TEST_LABEL_DIR)\n",
    "split_labels = [items.split('|')[0] for items in read_data.Finding_Labels]\n",
    "one_hot = MultiLabelBinarizer()\n",
    "test_labels = one_hot.fit_transform(split_labels)\n",
    "test_labels = test_labels[:3000]\n",
    "\n",
    "def create_batch(directory):\n",
    "    img_array = []\n",
    "    for img in tqdm(os.listdir(directory)):\n",
    "        path = os.path.join(directory, img)\n",
    "        img = tf.image.decode_png(path, channels = 1)\n",
    "        img = tf.image.resize_images(img, [IMG_SIZE, IMG_SIZE])\n",
    "        img_array.append(img)\n",
    "    return img_array\n",
    "\n",
    "training_img = create_batch(TRAIN_DIR)\n",
    "training_img = np.array(training_img)\n",
    "\n",
    "test_img = create_batch(TEST_DIR)\n",
    "test_img = np.array(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7db1595c3fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#models.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_img' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#Building the network\n",
    "models = models.Sequential()\n",
    "models.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (256, 256, 1))) #Input layer\n",
    "models.add(layers.MaxPooling2D((2,2)))\n",
    "models.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "models.add(layers.MaxPooling2D((2,2)))\n",
    "models.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "models.add(layers.MaxPooling2D((2,2)))\n",
    "models.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\n",
    "models.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "models.add(layers.Flatten())\n",
    "models.add(layers.Dense(512, activation = 'relu'))\n",
    "models.add(layers.Dense(15, activation = 'softmax'))\n",
    "\n",
    "#Configuring the model for training\n",
    "from keras import optimizers\n",
    "\n",
    "lr = 1e-4 #learning rate\n",
    "models.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr))\n",
    "\n",
    "#Training the model\n",
    "models.fit(training_img, training_label, epochs = 1, batch_size = 128)\n",
    "\n",
    "#models.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "URE18",
   "language": "python",
   "name": "ure18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
