{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Metric Analysis\n",
    "def true_accuracy(y_test, pred):\n",
    "    \n",
    "    pred = np.round_(pred)\n",
    "    pred = pred.astype(dtype = 'uint8')\n",
    "    \n",
    "    ft = pred == y_test\n",
    "    \n",
    "#    acc = []\n",
    "    \n",
    "#    counter = 0\n",
    "#    while counter < len(ft):\n",
    "#        if sum(ft[counter]) < 15:\n",
    "#            acc.append(0)\n",
    "#            counter += 1\n",
    "#        else:\n",
    "#           acc.append(1)\n",
    "#            counter += 1\n",
    "           \n",
    "    # Accuracy       \n",
    "    Acc = (sum(ft)/len(ft))\n",
    "    \n",
    "   # print('\\t Complete Label Accuracy: ', (Acc * 100), '%')\n",
    "    \n",
    "   # print('Sum of Fully Correct Predictions: ', sum(acc))\n",
    "   # print('\\t\\t    Total Labels: ', len(acc))\n",
    "    \n",
    "    if Acc == 0:\n",
    "        message = 'Feels Devastating (ﾉಥ益ಥ）ﾉ ┻━┻'\n",
    "        \n",
    "    elif Acc > 0 and Acc < 50:\n",
    "        message = 'Feels Awful (੭ ˃̣̣̥ ㅂ˂̣̣̥)੭ु'\n",
    "        \n",
    "    elif Acc >= 50 and Acc < 60:\n",
    "        message = 'Feels Bad (⌯˃̶᷄ ﹏ ˂̶᷄⌯)'\n",
    "        \n",
    "    elif Acc >= 60 and Acc < 70:\n",
    "        message = 'Feels Meh... ┬─┬ノ(ಠ_ಠノ)'\n",
    "    \n",
    "    elif Acc >= 70 and Acc < 80:\n",
    "        message = 'Feels Ok ʕ ·㉨·ʔ'\n",
    "    \n",
    "    elif Acc >= 80 and Acc < 90:\n",
    "        message = 'Feels Better (^._.^)ﾉ'\n",
    "        \n",
    "    elif Acc >= 90 and Acc < 95:\n",
    "        message = 'Feels Hopeful ( •́ ⍨ •̀)'\n",
    "        \n",
    "    elif Acc >= 95 and Acc < 98:\n",
    "        message = 'Feels Good ヽ|･ω･|ゞ'\n",
    "        \n",
    "    elif Acc >= 98:\n",
    "        message = 'Feels Great! ᕙ( * •̀ ᗜ •́ * )ᕗ'\n",
    "        \n",
    "    print('\\n', message)\n",
    "    \n",
    "    return Acc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "og_class_weights = [{0: 1, 1: 9.69980},\n",
    "                 {0: 1, 1: 40.38905},\n",
    "                 {0: 1, 1: 24.02400},\n",
    "                 {0: 1, 1: 48.68432},\n",
    "                 {0: 1, 1: 8.41931},\n",
    "                 {0: 1, 1: 44.56280},\n",
    "                 {0: 1, 1: 66.50059},\n",
    "                 {0: 1, 1: 493.92071},\n",
    "                 {0: 1, 1: 5.63587},\n",
    "                 {0: 1, 1: 19.39121},\n",
    "                 {0: 1, 1: 1.00000},\n",
    "                 {0: 1, 1: 17.70968},\n",
    "                 {0: 1, 1: 33.12260},\n",
    "                 {0: 1, 1: 78.35080},\n",
    "                 {0: 1, 1: 21.14674}]\n",
    "\n",
    "Atelectasis        = 112120 / 3790\n",
    "Cardiomegaly       = 112120 / 972\n",
    "Consolidation      = 112120 / 1188\n",
    "Edema              = 112120 / 588\n",
    "Effusion           = 112120 / 3617\n",
    "Emphysema          = 112120 / 783\n",
    "Fibrosis           = 112120 / 555\n",
    "Hernia             = 112120 / 88\n",
    "Infiltration       = 112120 / 8666\n",
    "Mass               = 112120 / 2004\n",
    "No_Finding         = 112120 / 53911\n",
    "Nodule             = 112120 / 2478\n",
    "Pleural_Thickening = 112120 / 983\n",
    "Pneumonia          = 112120 / 283\n",
    "Pneumothorax       = 112120 / 1942\n",
    "\n",
    "print('       Atelectasis Weight: ', Atelectasis)       \n",
    "print('      Cardiomegaly Weight: ', Cardiomegaly)      \n",
    "print('     Consolidation Weight: ', Consolidation)     \n",
    "print('             Edema Weight: ', Edema)             \n",
    "print('          Effusion Weight: ', Effusion)          \n",
    "print('         Emphysema Weight: ', Emphysema)         \n",
    "print('          Fibrosis Weight: ', Fibrosis)          \n",
    "print('            Hernia Weight: ', Hernia)            \n",
    "print('      Infiltration Weight: ', Infiltration)      \n",
    "print('              Mass Weight: ', Mass)              \n",
    "print('        No_Finding Weight: ', No_Finding)        \n",
    "print('            Nodule Weight: ', Nodule)            \n",
    "print('Pleural_Thickening Weight: ', Pleural_Thickening)\n",
    "print('         Pneumonia Weight: ', Pneumonia)         \n",
    "print('      Pneumothorax Weight: ', Pneumothorax)\n",
    "\n",
    "yung_class_weights = [{0: 1, 1: Atelectasis},\n",
    "                      {0: 1, 1: Cardiomegaly},\n",
    "                      {0: 1, 1: Consolidation},\n",
    "                      {0: 1, 1: Edema},\n",
    "                      {0: 1, 1: Effusion},\n",
    "                      {0: 1, 1: Emphysema},\n",
    "                      {0: 1, 1: Fibrosis},\n",
    "                      {0: 1, 1: Hernia},\n",
    "                      {0: 1, 1: Infiltration},\n",
    "                      {0: 1, 1: Mass},\n",
    "                      {0: 1, 1: No_Finding},\n",
    "                      {0: 1, 1: Nodule},\n",
    "                      {0: 1, 1: Pleural_Thickening},\n",
    "                      {0: 1, 1: Pneumonia},\n",
    "                      {0: 1, 1: Pneumothorax}]\n",
    "\n",
    "exp_weights = [{0:1., 1: 94.086},\n",
    "              {0:1., 1: 1631.2754},\n",
    "              {0:1., 1: 577.1525},\n",
    "              {0:1., 1: 2370.163},\n",
    "              {0:1., 1: 70.8848},\n",
    "              {0:1., 1: 1985.8431},\n",
    "              {0:1., 1: 4422.3285},\n",
    "              {0:1., 1: 243957.6678},\n",
    "              {0:1., 1: 31.76303},\n",
    "              {0:1., 1: 376.019025},\n",
    "              {0:1., 1: 1.},\n",
    "              {0:1., 1: 313.63277},\n",
    "              {0:1., 1: 1097.106631},\n",
    "              {0:1., 1: 6138.84786},\n",
    "              {0:1., 1: 447.1846}]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Residual Network\n",
    "\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "img_channels = 1\n",
    "\n",
    "#\n",
    "# network params\n",
    "#\n",
    "\n",
    "cardinality = 4\n",
    "\n",
    "\n",
    "def residual_network(x):\n",
    "    \"\"\"\n",
    "    ResNeXt by default. For ResNet set `cardinality` = 1 above.\n",
    "    \n",
    "    \"\"\"\n",
    "    def add_common_layers(y):\n",
    "        #y = layers.BatchNormalization()(y)\n",
    "        y = layers.ReLU()(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def grouped_convolution(y, nb_channels, _strides):\n",
    "        # when `cardinality` == 1 this is just a standard convolution\n",
    "        if cardinality == 1:\n",
    "            return layers.Conv2D(nb_channels, kernel_size=(3, 3), strides=_strides, padding='same')(y)\n",
    "        \n",
    "        assert not nb_channels % cardinality\n",
    "        _d = nb_channels // cardinality\n",
    "\n",
    "        # in a grouped convolution layer, input and output channels are divided into `cardinality` groups,\n",
    "        # and convolutions are separately performed within each group\n",
    "        groups = []\n",
    "        for j in range(cardinality):\n",
    "            group = layers.Lambda(lambda z: z[:, :, :, j * _d:j * _d + _d])(y)\n",
    "            groups.append(layers.Conv2D(_d, kernel_size=(3, 3), strides=_strides, padding='same')(group))\n",
    "            \n",
    "        # the grouped convolutional layer concatenates them as the outputs of the layer\n",
    "        y = layers.concatenate(groups)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def residual_block(y, nb_channels_in, nb_channels_out, _strides=(1, 1), _project_shortcut=False):\n",
    "        \"\"\"\n",
    "        Our network consists of a stack of residual blocks. These blocks have the same topology,\n",
    "        and are subject to two simple rules:\n",
    "        - If producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes).\n",
    "        - Each time the spatial map is down-sampled by a factor of 2, the width of the blocks is multiplied by a factor of 2.\n",
    "        \"\"\"\n",
    "        shortcut = y\n",
    "\n",
    "        # we modify the residual building block as a bottleneck design to make the network more economical\n",
    "        y = layers.Conv2D(nb_channels_in, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        # ResNeXt (identical to ResNet when `cardinality` == 1)\n",
    "        y = grouped_convolution(y, nb_channels_in, _strides=_strides)\n",
    "        y = add_common_layers(y)\n",
    "\n",
    "        y = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=(1, 1), padding='same')(y)\n",
    "        # batch normalization is employed after aggregating the transformations and before adding to the shortcut\n",
    "        y = layers.BatchNormalization()(y)\n",
    "\n",
    "        # identity shortcuts used directly when the input and output are of the same dimensions\n",
    "        if _project_shortcut or _strides != (1, 1):\n",
    "            # when the dimensions increase projection shortcut is used to match dimensions (done by 1×1 convolutions)\n",
    "            # when the shortcuts go across feature maps of two sizes, they are performed with a stride of 2\n",
    "            shortcut = layers.Conv2D(nb_channels_out, kernel_size=(1, 1), strides=_strides, padding='same')(shortcut)\n",
    "            shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "        y = layers.add([shortcut, y])\n",
    "\n",
    "        # relu is performed right after each batch normalization,\n",
    "        # expect for the output of the block where relu is performed after the adding to the shortcut\n",
    "        y = layers.ReLU()(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "    # conv block 1\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = add_common_layers(x)    \n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same')(x)\n",
    "    \n",
    "    # residual block\n",
    "    for i in range(3):\n",
    "        project_shortcut = (i == 0)\n",
    "        x = residual_block(x, 16, 32, _project_shortcut=project_shortcut)\n",
    "\n",
    "    # conv block 2\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = add_common_layers(x)    \n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same')(x)\n",
    "    \n",
    "    # conv block 3\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = add_common_layers(x)    \n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=None, padding='same')(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(4):\n",
    "        # down-sampling is performed by conv3_1, conv4_1, and conv5_1 with a stride of 2\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 32, 32, _strides=strides)\n",
    "\n",
    "    # conv4\n",
    "    for i in range(6):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 32, 64, _strides=strides)\n",
    "\n",
    "    # conv5\n",
    "    for i in range(3):\n",
    "        strides = (2, 2) if i == 0 else (1, 1)\n",
    "        x = residual_block(x, 64, 64, _strides=strides)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(16)(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "image_tensor = layers.Input(shape=(img_height, img_width, img_channels))\n",
    "network_output = residual_network(image_tensor)\n",
    "  \n",
    "model = models.Model(inputs=[image_tensor], outputs=[network_output])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "# v3: Using Categorical Accuracy as metrics\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 20, validation_split = 0.1, batch_size = 128)\n",
    "\n",
    "history_str = 'VGG_Doppleganger_v3_history'\n",
    "model_str   = 'VGG_Doppleganger_v3_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### vanilla_VGG_Dropouts\n",
    "\n",
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "# v6: Added Batch Normalization layers to each Block\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1, class_weight= class_weights )\n",
    "\n",
    "history_str = 'vanilla_VGG_Dropouts_v6_history'\n",
    "model_str   = 'vanilla_VGG_Dropouts_v6_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "print(Predictions)\n",
    "#Accuracy = true_accuracy(test_labels, Predictions)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### tiny_Inception\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(SeparableConv2D(8, (3, 3), \n",
    "                          kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation = 'elu', \n",
    "                          input_shape = (256, 256, 1)))\n",
    "model.add(SeparableConv2D(8, (3, 3), \n",
    "                          kernel_regularizer=regularizers.l2(0.001),\n",
    "                          activation = 'elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), \n",
    "                 kernel_regularizer=regularizers.l2(0.001),\n",
    "                 activation = 'elu'))\n",
    "model.add(Conv2D(32, (3, 3), \n",
    "                 kernel_regularizer=regularizers.l2(0.001),\n",
    "                 activation = 'elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(64, activation = 'elu'))\n",
    "model.add(Dense(15, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-3), \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['categorical_accuracy'])\n",
    "\n",
    "model_obj = model.fit(training_img, training_labels, \n",
    "                      epochs = 20, validation_split = (1/9), \n",
    "                      batch_size = 128, verbose = 1)\n",
    "\n",
    "Predictions = model.predict(test_img)\n",
    "Predictions = Predictions.astype(dtype = 'int32')\n",
    "\n",
    "Accuracy = true_accuracy(test_labels, Predictions)\n",
    "\n",
    "history_str = 'vanilla_reg_VGG_v4_history'\n",
    "model_str   = 'vanilla_reg_VGG_v4_30e'\n",
    "    \n",
    "save_model(model_obj, history_str, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
