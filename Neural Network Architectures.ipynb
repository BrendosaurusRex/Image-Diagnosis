{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "from keras import models, optimizers, layers, regularizers, metrics\n",
    "from keras.models import model_from_json\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save baseline model architecture and weights\n",
    "def save_base(model_name):\n",
    "    model_str = str(input(\"Save model as: \"))\n",
    "\n",
    "    # serialize model to JSON\n",
    "    model_name = baseline.to_json()\n",
    "    with open(\"CNN Models/\" + model_str + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_name)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    baseline.save_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Saved \" + model_str + \" and weights to CNN Models folder\")\n",
    "    \n",
    "# Save Comparison model\n",
    "def save_model(model_name):\n",
    "    model_str = str(input(\"Save model as: \"))\n",
    "\n",
    "    # serialize model to JSON\n",
    "    model_name = model.to_json()\n",
    "    with open(\"CNN Models/\" + model_str + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_name)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Saved \" + model_str + \" and weights to CNN Models folder\")\n",
    "    \n",
    "# Load model architecture and weights NOTE: must compile again\n",
    "def load_model():\n",
    "    model_str = str(input(\"Name of model to load: \"))\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open('CNN Models/' + model_str + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"CNN Models/\" + model_str + \".h5\")\n",
    "    print(\"Loaded \" + model_str + \" and weights from CNN Models folder\")\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "# Write history object to a file using pickle\n",
    "def save_history(model_name):\n",
    "    hist_str = str(input(\"Save history as: \"))\n",
    "\n",
    "    pickle.dump(model_name.history, open('Training Histories/'+ hist_str + '.p', 'wb'))\n",
    "    \n",
    "    print(\"Saved \" + hist_str + \" to Training Histories folder\")\n",
    "    \n",
    "# Load history object\n",
    "def load_history():\n",
    "    hist_str = str(input(\"Name of history to load: \"))\n",
    "\n",
    "    loaded_history = pickle.load(open('Training Histories/' + hist_str + '.p', 'rb'))\n",
    "    \n",
    "    print(\"Loaded \" + hist_str + \" from Training Histories folder\")\n",
    "    \n",
    "    return loaded_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_1 = pickle.load(open('training_img_1.p', 'rb'))\n",
    "training_img_2 = pickle.load(open('training_img_2.p', 'rb'))\n",
    "training_img = np.append(training_img_1, training_img_2, axis = 0)\n",
    "\n",
    "test_img = pickle.load(open('pickle_test_img.p', 'rb'))\n",
    "\n",
    "training_labels = pickle.load(open('training_labels.p', 'rb'))\n",
    "test_labels = pickle.load(open('test_labels.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla ConvNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG_Doppleganger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly taken from VGG16 with 2D Spatial Dropout, Dropout, and fewer Dense layers\n",
    "'''\n",
    "accuracy\n",
    "'''\n",
    "VGG_Doppleganger = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "VGG_Doppleganger.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "VGG_Doppleganger.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "VGG_Doppleganger.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.MaxPooling2D((2, 2)))\n",
    "VGG_Doppleganger.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "VGG_Doppleganger.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "VGG_Doppleganger.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "VGG_Doppleganger.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "VGG_Doppleganger.add(layers.MaxPooling2D((2, 2)))\n",
    "VGG_Doppleganger.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "VGG_Doppleganger.add(layers.Flatten())\n",
    "VGG_Doppleganger.add(layers.Dense(64, activation='relu'))\n",
    "VGG_Doppleganger.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "VGG_Doppleganger.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "VGG_Doppleganger_history = VGG_Doppleganger.fit(training_img, training_labels, epochs = 40, validation_split = (1 / 9), batch_size = 128, verbose = 1)\n",
    "\n",
    "# VGG_Doppleganger\n",
    "\n",
    "save_history(VGG_Doppleganger_history)\n",
    "save_model(VGG_Doppleganger_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89696 samples, validate on 11212 samples\n",
      "Epoch 1/40\n",
      "89696/89696 [==============================] - 267s 3ms/step - loss: 0.6713 - acc: 0.9203 - val_loss: 0.4376 - val_acc: 0.9223\n",
      "Epoch 2/40\n",
      "89696/89696 [==============================] - 263s 3ms/step - loss: 0.3224 - acc: 0.9246 - val_loss: 0.3226 - val_acc: 0.9213\n",
      "Epoch 3/40\n",
      "89696/89696 [==============================] - 266s 3ms/step - loss: 0.2732 - acc: 0.9252 - val_loss: 0.2860 - val_acc: 0.9227\n",
      "Epoch 4/40\n",
      "89696/89696 [==============================] - 271s 3ms/step - loss: 0.2515 - acc: 0.9257 - val_loss: 0.2686 - val_acc: 0.9194\n",
      "Epoch 5/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2392 - acc: 0.9260 - val_loss: 0.2549 - val_acc: 0.9201\n",
      "Epoch 6/40\n",
      "89696/89696 [==============================] - 274s 3ms/step - loss: 0.2311 - acc: 0.9262 - val_loss: 0.2400 - val_acc: 0.9208\n",
      "Epoch 7/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2258 - acc: 0.9265 - val_loss: 0.2361 - val_acc: 0.9197\n",
      "Epoch 8/40\n",
      "89696/89696 [==============================] - 273s 3ms/step - loss: 0.2220 - acc: 0.9266 - val_loss: 0.2293 - val_acc: 0.9208\n",
      "Epoch 9/40\n",
      "89696/89696 [==============================] - 271s 3ms/step - loss: 0.2191 - acc: 0.9268 - val_loss: 0.2267 - val_acc: 0.9214\n",
      "Epoch 10/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2170 - acc: 0.9271 - val_loss: 0.2225 - val_acc: 0.9221\n",
      "Epoch 11/40\n",
      "89696/89696 [==============================] - 271s 3ms/step - loss: 0.2151 - acc: 0.9272 - val_loss: 0.2207 - val_acc: 0.9241\n",
      "Epoch 12/40\n",
      "89696/89696 [==============================] - 269s 3ms/step - loss: 0.2136 - acc: 0.9274 - val_loss: 0.2196 - val_acc: 0.9246\n",
      "Epoch 13/40\n",
      "89696/89696 [==============================] - 267s 3ms/step - loss: 0.2123 - acc: 0.9276 - val_loss: 0.2174 - val_acc: 0.9243\n",
      "Epoch 14/40\n",
      "89696/89696 [==============================] - 266s 3ms/step - loss: 0.2111 - acc: 0.9278 - val_loss: 0.2164 - val_acc: 0.9243\n",
      "Epoch 15/40\n",
      "89696/89696 [==============================] - 265s 3ms/step - loss: 0.2103 - acc: 0.9279 - val_loss: 0.2158 - val_acc: 0.9246\n",
      "Epoch 16/40\n",
      "89696/89696 [==============================] - 269s 3ms/step - loss: 0.2094 - acc: 0.9281 - val_loss: 0.2143 - val_acc: 0.9249\n",
      "Epoch 17/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2089 - acc: 0.9282 - val_loss: 0.2158 - val_acc: 0.9235\n",
      "Epoch 18/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2083 - acc: 0.9283 - val_loss: 0.2145 - val_acc: 0.9242\n",
      "Epoch 19/40\n",
      "89696/89696 [==============================] - 267s 3ms/step - loss: 0.2077 - acc: 0.9284 - val_loss: 0.2151 - val_acc: 0.9245\n",
      "Epoch 20/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2073 - acc: 0.9285 - val_loss: 0.2132 - val_acc: 0.9252\n",
      "Epoch 21/40\n",
      "89696/89696 [==============================] - 272s 3ms/step - loss: 0.2067 - acc: 0.9286 - val_loss: 0.2118 - val_acc: 0.9252\n",
      "Epoch 22/40\n",
      "89696/89696 [==============================] - 268s 3ms/step - loss: 0.2062 - acc: 0.9288 - val_loss: 0.2127 - val_acc: 0.9252\n",
      "Epoch 23/40\n",
      "89696/89696 [==============================] - 268s 3ms/step - loss: 0.2057 - acc: 0.9291 - val_loss: 0.2177 - val_acc: 0.9224\n",
      "Epoch 24/40\n",
      "89696/89696 [==============================] - 263s 3ms/step - loss: 0.2055 - acc: 0.9291 - val_loss: 0.2118 - val_acc: 0.9255\n",
      "Epoch 25/40\n",
      "89696/89696 [==============================] - 269s 3ms/step - loss: 0.2050 - acc: 0.9292 - val_loss: 0.2130 - val_acc: 0.9245\n",
      "Epoch 26/40\n",
      "89696/89696 [==============================] - 268s 3ms/step - loss: 0.2047 - acc: 0.9294 - val_loss: 0.2105 - val_acc: 0.9253\n",
      "Epoch 27/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2043 - acc: 0.9294 - val_loss: 0.2105 - val_acc: 0.9258\n",
      "Epoch 28/40\n",
      "89696/89696 [==============================] - 260s 3ms/step - loss: 0.2040 - acc: 0.9296 - val_loss: 0.2152 - val_acc: 0.9244\n",
      "Epoch 29/40\n",
      "89696/89696 [==============================] - 265s 3ms/step - loss: 0.2037 - acc: 0.9296 - val_loss: 0.2113 - val_acc: 0.9252\n",
      "Epoch 30/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2033 - acc: 0.9298 - val_loss: 0.2104 - val_acc: 0.9253\n",
      "Epoch 31/40\n",
      "89696/89696 [==============================] - 267s 3ms/step - loss: 0.2031 - acc: 0.9297 - val_loss: 0.2094 - val_acc: 0.9259\n",
      "Epoch 32/40\n",
      "89696/89696 [==============================] - 266s 3ms/step - loss: 0.2028 - acc: 0.9299 - val_loss: 0.2101 - val_acc: 0.9254\n",
      "Epoch 33/40\n",
      "89696/89696 [==============================] - 267s 3ms/step - loss: 0.2026 - acc: 0.9299 - val_loss: 0.2138 - val_acc: 0.9244\n",
      "Epoch 34/40\n",
      "89696/89696 [==============================] - 272s 3ms/step - loss: 0.2023 - acc: 0.9301 - val_loss: 0.2098 - val_acc: 0.9253\n",
      "Epoch 35/40\n",
      "89696/89696 [==============================] - 265s 3ms/step - loss: 0.2021 - acc: 0.9301 - val_loss: 0.2114 - val_acc: 0.9256\n",
      "Epoch 36/40\n",
      "89696/89696 [==============================] - 261s 3ms/step - loss: 0.2020 - acc: 0.9302 - val_loss: 0.2087 - val_acc: 0.9262\n",
      "Epoch 37/40\n",
      "89696/89696 [==============================] - 266s 3ms/step - loss: 0.2018 - acc: 0.9302 - val_loss: 0.2096 - val_acc: 0.9256\n",
      "Epoch 38/40\n",
      "89696/89696 [==============================] - 252s 3ms/step - loss: 0.2016 - acc: 0.9303 - val_loss: 0.2136 - val_acc: 0.9245\n",
      "Epoch 39/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2013 - acc: 0.9303 - val_loss: 0.2089 - val_acc: 0.9259\n",
      "Epoch 40/40\n",
      "89696/89696 [==============================] - 270s 3ms/step - loss: 0.2014 - acc: 0.9302 - val_loss: 0.2093 - val_acc: 0.9257\n"
     ]
    }
   ],
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "'''\n",
    "accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "VGG_Doppleganger_v2_history = model.fit(training_img, training_labels, epochs = 40, validation_split = (1 / 9), batch_size = 128, verbose = 1)\n",
    "\n",
    "# VGG_Doppleganger_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save history as: VGG_Doppleganger_v2_history\n",
      "Saved VGG_Doppleganger_v2_history to Training Histories folder\n",
      "Save model as: VGG_Doppleganger_v2_40e\n",
      "Saved VGG_Doppleganger_v2_40e and weights to CNN Models folder\n"
     ]
    }
   ],
   "source": [
    "save_history(VGG_Doppleganger_v2_history)\n",
    "save_model(VGG_Doppleganger_v2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Removed Conv2D layer in Block 3 and moved SpDrop layer to Block 1\n",
    "# v3: Using Categorical Accuracy as metrics\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "VGG_Doppleganger_v3_history = model.fit(training_img, training_labels, epochs = 40, validation_split = (1 / 9), batch_size = 128)\n",
    "\n",
    "# VGG_Doppleganger_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla_VGG_Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89696 samples, validate on 11212 samples\n",
      "Epoch 1/30\n",
      "89696/89696 [==============================] - 226s 3ms/step - loss: 0.4351 - categorical_accuracy: 0.5198 - val_loss: 0.3634 - val_categorical_accuracy: 0.5100\n",
      "Epoch 2/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2909 - categorical_accuracy: 0.5335 - val_loss: 0.3845 - val_categorical_accuracy: 0.5022\n",
      "Epoch 3/30\n",
      "89696/89696 [==============================] - 221s 2ms/step - loss: 0.2550 - categorical_accuracy: 0.5327 - val_loss: 0.3738 - val_categorical_accuracy: 0.4959\n",
      "Epoch 4/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2407 - categorical_accuracy: 0.5314 - val_loss: 0.3251 - val_categorical_accuracy: 0.4973\n",
      "Epoch 5/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2322 - categorical_accuracy: 0.5307 - val_loss: 0.2977 - val_categorical_accuracy: 0.4913\n",
      "Epoch 6/30\n",
      "89696/89696 [==============================] - 221s 2ms/step - loss: 0.2265 - categorical_accuracy: 0.5296 - val_loss: 0.2907 - val_categorical_accuracy: 0.4923\n",
      "Epoch 7/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2222 - categorical_accuracy: 0.5306 - val_loss: 0.2657 - val_categorical_accuracy: 0.4970\n",
      "Epoch 8/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2186 - categorical_accuracy: 0.5308 - val_loss: 0.2779 - val_categorical_accuracy: 0.5006\n",
      "Epoch 9/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2161 - categorical_accuracy: 0.5312 - val_loss: 0.2456 - val_categorical_accuracy: 0.4979\n",
      "Epoch 10/30\n",
      "89696/89696 [==============================] - 221s 2ms/step - loss: 0.2137 - categorical_accuracy: 0.5319 - val_loss: 0.2513 - val_categorical_accuracy: 0.4985\n",
      "Epoch 11/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2116 - categorical_accuracy: 0.5321 - val_loss: 0.2276 - val_categorical_accuracy: 0.5057\n",
      "Epoch 12/30\n",
      "89696/89696 [==============================] - 221s 2ms/step - loss: 0.2097 - categorical_accuracy: 0.5344 - val_loss: 0.2385 - val_categorical_accuracy: 0.5041\n",
      "Epoch 13/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2080 - categorical_accuracy: 0.5345 - val_loss: 0.2511 - val_categorical_accuracy: 0.4964\n",
      "Epoch 14/30\n",
      "89696/89696 [==============================] - 223s 2ms/step - loss: 0.2066 - categorical_accuracy: 0.5357 - val_loss: 0.2243 - val_categorical_accuracy: 0.5026\n",
      "Epoch 15/30\n",
      "89696/89696 [==============================] - 224s 2ms/step - loss: 0.2049 - categorical_accuracy: 0.5359 - val_loss: 0.2409 - val_categorical_accuracy: 0.4915\n",
      "Epoch 16/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2036 - categorical_accuracy: 0.5368 - val_loss: 0.2195 - val_categorical_accuracy: 0.5011\n",
      "Epoch 17/30\n",
      "89696/89696 [==============================] - 221s 2ms/step - loss: 0.2024 - categorical_accuracy: 0.5380 - val_loss: 0.2159 - val_categorical_accuracy: 0.5095\n",
      "Epoch 18/30\n",
      "89696/89696 [==============================] - 223s 2ms/step - loss: 0.2014 - categorical_accuracy: 0.5392 - val_loss: 0.2246 - val_categorical_accuracy: 0.4946\n",
      "Epoch 19/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.2003 - categorical_accuracy: 0.5393 - val_loss: 0.2174 - val_categorical_accuracy: 0.4841\n",
      "Epoch 20/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1993 - categorical_accuracy: 0.5401 - val_loss: 0.2144 - val_categorical_accuracy: 0.4849\n",
      "Epoch 21/30\n",
      "89696/89696 [==============================] - 224s 2ms/step - loss: 0.1984 - categorical_accuracy: 0.5409 - val_loss: 0.2112 - val_categorical_accuracy: 0.5050\n",
      "Epoch 22/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1976 - categorical_accuracy: 0.5407 - val_loss: 0.2168 - val_categorical_accuracy: 0.4964\n",
      "Epoch 23/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1967 - categorical_accuracy: 0.5421 - val_loss: 0.2105 - val_categorical_accuracy: 0.4914\n",
      "Epoch 24/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1959 - categorical_accuracy: 0.5426 - val_loss: 0.2107 - val_categorical_accuracy: 0.5002\n",
      "Epoch 25/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1951 - categorical_accuracy: 0.5437 - val_loss: 0.2159 - val_categorical_accuracy: 0.4941\n",
      "Epoch 26/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1943 - categorical_accuracy: 0.5442 - val_loss: 0.2094 - val_categorical_accuracy: 0.5064\n",
      "Epoch 27/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1937 - categorical_accuracy: 0.5450 - val_loss: 0.2068 - val_categorical_accuracy: 0.5031\n",
      "Epoch 28/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1929 - categorical_accuracy: 0.5459 - val_loss: 0.2069 - val_categorical_accuracy: 0.5036\n",
      "Epoch 29/30\n",
      "89696/89696 [==============================] - 222s 2ms/step - loss: 0.1923 - categorical_accuracy: 0.5474 - val_loss: 0.2084 - val_categorical_accuracy: 0.5045\n",
      "Epoch 30/30\n",
      "89696/89696 [==============================] - 223s 2ms/step - loss: 0.1918 - categorical_accuracy: 0.5475 - val_loss: 0.2074 - val_categorical_accuracy: 0.4965\n"
     ]
    }
   ],
   "source": [
    "# Based on VGG with half reg'd layers and Dropout layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_VGG_Dropouts_history = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "'''\n",
    "vanilla_VGG_Dropouts\n",
    "history: vanilla_VGG_Dropouts_history\n",
    "model: vanilla_VGG_Dropouts_30e\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save history as: vanilla_VGG_Dropouts_history\n",
      "Saved vanilla_VGG_Dropouts_history to Training Histories folder\n",
      "Save model as: vanilla_VGG_Dropouts_30e\n",
      "Saved vanilla_VGG_Dropouts_30e and weights to CNN Models folder\n"
     ]
    }
   ],
   "source": [
    "save_history(vanilla_VGG_Dropouts_history)\n",
    "save_model(vanilla_VGG_Dropouts_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89696 samples, validate on 11212 samples\n",
      "Epoch 1/30\n",
      "89696/89696 [==============================] - 230s 3ms/step - loss: 0.4561 - categorical_accuracy: 0.5301 - val_loss: 0.5632 - val_categorical_accuracy: 0.5098\n",
      "Epoch 2/30\n",
      "89696/89696 [==============================] - 228s 3ms/step - loss: 0.3209 - categorical_accuracy: 0.5365 - val_loss: 0.4090 - val_categorical_accuracy: 0.5098\n",
      "Epoch 3/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.2763 - categorical_accuracy: 0.5335 - val_loss: 0.3647 - val_categorical_accuracy: 0.5060\n",
      "Epoch 4/30\n",
      "89696/89696 [==============================] - 228s 3ms/step - loss: 0.2543 - categorical_accuracy: 0.5309 - val_loss: 0.3250 - val_categorical_accuracy: 0.5039\n",
      "Epoch 5/30\n",
      "89696/89696 [==============================] - 227s 3ms/step - loss: 0.2413 - categorical_accuracy: 0.5298 - val_loss: 0.2790 - val_categorical_accuracy: 0.5083\n",
      "Epoch 6/30\n",
      "89696/89696 [==============================] - 232s 3ms/step - loss: 0.2326 - categorical_accuracy: 0.5298 - val_loss: 0.2438 - val_categorical_accuracy: 0.5047\n",
      "Epoch 7/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.2262 - categorical_accuracy: 0.5287 - val_loss: 0.2353 - val_categorical_accuracy: 0.5090\n",
      "Epoch 8/30\n",
      "89696/89696 [==============================] - 228s 3ms/step - loss: 0.2212 - categorical_accuracy: 0.5286 - val_loss: 0.2299 - val_categorical_accuracy: 0.5099\n",
      "Epoch 9/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.2172 - categorical_accuracy: 0.5301 - val_loss: 0.2292 - val_categorical_accuracy: 0.5043\n",
      "Epoch 10/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.2139 - categorical_accuracy: 0.5299 - val_loss: 0.2243 - val_categorical_accuracy: 0.5061\n",
      "Epoch 11/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.2110 - categorical_accuracy: 0.5311 - val_loss: 0.2254 - val_categorical_accuracy: 0.5024\n",
      "Epoch 12/30\n",
      "89696/89696 [==============================] - 228s 3ms/step - loss: 0.2090 - categorical_accuracy: 0.5315 - val_loss: 0.2203 - val_categorical_accuracy: 0.4998\n",
      "Epoch 13/30\n",
      "89696/89696 [==============================] - 228s 3ms/step - loss: 0.2069 - categorical_accuracy: 0.5311 - val_loss: 0.2181 - val_categorical_accuracy: 0.5087\n",
      "Epoch 14/30\n",
      "89696/89696 [==============================] - 230s 3ms/step - loss: 0.2052 - categorical_accuracy: 0.5331 - val_loss: 0.2171 - val_categorical_accuracy: 0.5087\n",
      "Epoch 15/30\n",
      "89696/89696 [==============================] - 230s 3ms/step - loss: 0.2036 - categorical_accuracy: 0.5335 - val_loss: 0.2150 - val_categorical_accuracy: 0.4988\n",
      "Epoch 16/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.2022 - categorical_accuracy: 0.5352 - val_loss: 0.2125 - val_categorical_accuracy: 0.5074\n",
      "Epoch 17/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.2010 - categorical_accuracy: 0.5359 - val_loss: 0.2122 - val_categorical_accuracy: 0.5022\n",
      "Epoch 18/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.2000 - categorical_accuracy: 0.5365 - val_loss: 0.2092 - val_categorical_accuracy: 0.5066\n",
      "Epoch 19/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1988 - categorical_accuracy: 0.5371 - val_loss: 0.2113 - val_categorical_accuracy: 0.5088\n",
      "Epoch 20/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1979 - categorical_accuracy: 0.5389 - val_loss: 0.2079 - val_categorical_accuracy: 0.5077\n",
      "Epoch 21/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1970 - categorical_accuracy: 0.5392 - val_loss: 0.2095 - val_categorical_accuracy: 0.5016\n",
      "Epoch 22/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1962 - categorical_accuracy: 0.5395 - val_loss: 0.2124 - val_categorical_accuracy: 0.5078\n",
      "Epoch 23/30\n",
      "89696/89696 [==============================] - 228s 3ms/step - loss: 0.1955 - categorical_accuracy: 0.5396 - val_loss: 0.2111 - val_categorical_accuracy: 0.5056\n",
      "Epoch 24/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1948 - categorical_accuracy: 0.5408 - val_loss: 0.2059 - val_categorical_accuracy: 0.5014\n",
      "Epoch 25/30\n",
      "89696/89696 [==============================] - 232s 3ms/step - loss: 0.1940 - categorical_accuracy: 0.5424 - val_loss: 0.2084 - val_categorical_accuracy: 0.5051\n",
      "Epoch 26/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1934 - categorical_accuracy: 0.5437 - val_loss: 0.2075 - val_categorical_accuracy: 0.5058\n",
      "Epoch 27/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1928 - categorical_accuracy: 0.5428 - val_loss: 0.2055 - val_categorical_accuracy: 0.5042\n",
      "Epoch 28/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1921 - categorical_accuracy: 0.5446 - val_loss: 0.2063 - val_categorical_accuracy: 0.5055\n",
      "Epoch 29/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1912 - categorical_accuracy: 0.5453 - val_loss: 0.2042 - val_categorical_accuracy: 0.5017\n",
      "Epoch 30/30\n",
      "89696/89696 [==============================] - 229s 3ms/step - loss: 0.1907 - categorical_accuracy: 0.5461 - val_loss: 0.2075 - val_categorical_accuracy: 0.5087\n"
     ]
    }
   ],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "model.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "model.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "model.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_VGG_Dropouts_v2_history = model.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "'''\n",
    " vanilla_VGG_Dropouts_v2\n",
    " history: vanilla_VGG_Dropouts_v2_history\n",
    " model: vanilla_VGG_Dropouts_v2_30e\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save history as: vanilla_VGG_Dropouts_v2_history\n",
      "Saved vanilla_VGG_Dropouts_v2_history to Training Histories folder\n",
      "Save model as: vanilla_VGG_Dropouts_v2_30e\n",
      "Saved vanilla_VGG_Dropouts_v2_30e and weights to CNN Models folder\n"
     ]
    }
   ],
   "source": [
    "save_history(vanilla_VGG_Dropouts_v2_history)\n",
    "save_model(vanilla_VGG_Dropouts_v2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "vanilla_VGG_Dropouts_v3 = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Flatten())\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_VGG_Dropouts_v3.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "vanilla_VGG_Dropouts_v3.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_VGG_Dropouts_v3_history = vanilla_VGG_Dropouts_v3.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "# vanilla_VGG_Dropouts_v3\n",
    "\n",
    "save_history(vanilla_VGG_Dropouts_v3_history)\n",
    "save_model(vanilla_VGG_Dropouts_v3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "vanilla_VGG_Dropouts_v4 = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.SpatialDropout2D(0.5, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Dropout(0.5))\n",
    "\n",
    "# Output Block\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Flatten())\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_VGG_Dropouts_v4.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "vanilla_VGG_Dropouts_v4.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_VGG_Dropouts_v4_history = vanilla_VGG_Dropouts_v4.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "# vanilla_VGG_Dropouts_v4\n",
    "\n",
    "save_history(vanilla_VGG_Dropouts_v4_history)\n",
    "save_model(vanilla_VGG_Dropouts_v4_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "vanilla_VGG_Dropouts_v5 = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Flatten())\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_VGG_Dropouts_v5.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "vanilla_VGG_Dropouts_v5.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_VGG_Dropouts_v5_history = vanilla_VGG_Dropouts_v5.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "# vanilla_VGG_Dropouts_v5\n",
    "\n",
    "save_history(vanilla_VGG_Dropouts_v5_history)\n",
    "save_model(vanilla_VGG_Dropouts_v5_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added 2D Sp Dropout to Block 1\n",
    "# v3: Added reg's to all layers\n",
    "# v4: Changed Regularizer Weight Penalty (0.001 -> 0.005)\n",
    "# v5: Added Dropout to all layers previously without, changed percentage\n",
    "# v6: Added Batch Normalization layers to each Block\n",
    "vanilla_VGG_Dropouts_v6 = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.BatchNormalization())\n",
    "vanilla_VGG_Dropouts_v6.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 2\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.BatchNormalization())\n",
    "vanilla_VGG_Dropouts_v6.add(layers.SpatialDropout2D(0.25, data_format = 'channels_last'))\n",
    "\n",
    "# Block 3\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.BatchNormalization())\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 4\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.BatchNormalization())\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Dropout(0.375))\n",
    "\n",
    "# Block 5\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.BatchNormalization())\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Dropout(0.375))\n",
    "\n",
    "# Output Block\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Flatten())\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_VGG_Dropouts_v6.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "\n",
    "vanilla_VGG_Dropouts_v6.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_VGG_Dropouts_v6_history = vanilla_VGG_Dropouts_v6.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "# vanilla_VGG_Dropouts_v6\n",
    "\n",
    "save_history(vanilla_VGG_Dropouts_v6_history)\n",
    "save_model(vanilla_VGG_Dropouts_v6_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanilla_reg_VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeled after VGGNet with half reg'd layers\n",
    "vanilla_reg_VGG = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_reg_VGG.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "vanilla_reg_VGG.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "vanilla_reg_VGG.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "vanilla_reg_VGG.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "vanilla_reg_VGG.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "vanilla_reg_VGG.add(layers.Flatten())\n",
    "vanilla_reg_VGG.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_reg_VGG.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "vanilla_reg_VGG.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_reg_VGG_history = vanilla_reg_VGG.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "# vanilla_reg_VGG\n",
    "\n",
    "save_history(vanilla_reg_VGG_history)\n",
    "save_model(vanilla_reg_VGG_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "'''\n",
    "categorical_accuracy\n",
    "'''\n",
    "vanilla_reg_VGG_v2 = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "vanilla_reg_VGG_v2.add(layers.Flatten())\n",
    "vanilla_reg_VGG_v2.add(layers.Dense(64, activation='relu'))\n",
    "vanilla_reg_VGG_v2.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "vanilla_reg_VGG_v2.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_reg_VGG_v2_history = vanilla_reg_VGG_v2.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "# vanilla_reg_VGG_v2\n",
    "\n",
    "save_history(vanilla_reg_VGG_v2_history)\n",
    "save_model(vanilla_reg_VGG_v2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "vanilla_reg_VGG_v3 = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 4\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 5\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Output Block\n",
    "vanilla_reg_VGG_v3.add(layers.Flatten())\n",
    "vanilla_reg_VGG_v3.add(layers.Dense(32, activation='relu'))\n",
    "vanilla_reg_VGG_v3.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "vanilla_reg_VGG_v3.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_reg_VGG_v3_history = vanilla_reg_VGG_v3.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "# vanilla_reg_VGG_v3\n",
    "\n",
    "save_history(vanilla_reg_VGG_v3_history)\n",
    "save_model(vanilla_reg_VGG_v3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2: Added reg's to all layers\n",
    "# v3: Changed No. of Outputs in Conv and Dense layers in Block 5 and Output\n",
    "# v4: Added Batch Normalization to all layers\n",
    "vanilla_reg_VGG_v4 = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(16, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_reg_VGG_v4.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 2\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_reg_VGG_v4.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 3\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_reg_VGG_v4.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 4\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_reg_VGG_v4.add(layers.BatchNormalization())\n",
    "\n",
    "# Block 5\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.MaxPooling2D((2, 2)))\n",
    "vanilla_reg_VGG_v4.add(layers.BatchNormalization())\n",
    "\n",
    "# Output Block\n",
    "vanilla_reg_VGG_v4.add(layers.Flatten())\n",
    "vanilla_reg_VGG_v4.add(layers.Dense(32, activation='relu'))\n",
    "vanilla_reg_VGG_v4.add(layers.Dense(15, activation='sigmoid'))\n",
    "\n",
    "vanilla_reg_VGG_v4.compile(optimizer = optimizers.RMSprop(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['categorical_accuracy'])\n",
    "\n",
    "vanilla_reg_VGG_v4_history = vanilla_reg_VGG_v4.fit(training_img, training_labels, epochs = 30, validation_split = (1 / 9), batch_size = 256, verbose = 1)\n",
    "\n",
    "# vanilla_reg_VGG_v4\n",
    "\n",
    "save_history(vanilla_reg_VGG_v4_history)\n",
    "save_model(vanilla_reg_VGG_v4_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
