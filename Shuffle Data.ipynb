{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run All Cells Once For Shuffling Data\n",
    "-Change Directory Paths if necessary (especially TRAIN_LABEL_DIR)\n",
    "\n",
    "-Should have pickle files for training_img_1/2, and test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.image as img\n",
    "from tqdm import tqdm\n",
    "import os, cv2\n",
    "np.set_printoptions(threshold = np.nan)\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config = config)\n",
    "\n",
    "TRAIN_DIR = 'C:\\\\Users\\\\rocke\\\\URE18\\\\Images'\n",
    "TEST_DIR = 'C:\\\\Users\\\\rocke\\\\URE18\\\\Test Images'\n",
    "TRAIN_LABEL_DIR = 'Data_Entry_2017.csv'\n",
    "IMG_SIZE = 256\n",
    "\n",
    "#### Load with pickle instead of processing images again\n",
    "training_img_1 = pickle.load(open('training_img_1.p', 'rb'))\n",
    "training_img_2 = pickle.load(open('training_img_2.p', 'rb'))\n",
    "training_img = np.append(training_img_1, training_img_2, axis = 0)\n",
    "\n",
    "test_img = pickle.load(open('pickle_test_img.p', 'rb'))\n",
    "\n",
    "#training_labels = pickle.load(open('training_labels.p', 'rb'))\n",
    "#test_labels = pickle.load(open('test_labels.p', 'rb'))\n",
    "\n",
    "\n",
    "all_img = np.append(test_img, training_img, axis = 0)\n",
    "#print(all_img.shape)\n",
    "\n",
    "read_data = pd.read_csv(TRAIN_LABEL_DIR)\n",
    "split_labels = [items.split('|') for items in read_data.Finding_Labels]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "str_array = np.hstack(split_labels)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(str_array)\n",
    "#print(integer_encoded)\n",
    "onehot_encoder = OneHotEncoder(sparse = False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "#print(onehot_encoded[:10])\n",
    "\n",
    "onehot_encoded = onehot_encoded.astype('int32')\n",
    "\n",
    "#all_img = np.append((pickle.load(open('all_img.p', 'rb'))), (pickle.load(open('all_img_2.p', 'rb'))), axis = 0)\n",
    "\n",
    "#onehot_encoded = pickle.load(open('onehot_encoded.p', 'rb'))\n",
    "\n",
    "shuffling_data = []\n",
    "index = 0\n",
    "\n",
    "for i in range(0, len(all_img)):\n",
    "    for label in split_labels[i]:\n",
    "        shuffling_data.append((onehot_encoded[index], all_img[i]))\n",
    "        index += 1\n",
    "\n",
    "shuffling_array = np.array(shuffling_data)\n",
    "\n",
    "shuffling_array.shape\n",
    "\n",
    "pickle.dump(shuffling_array[:20000], open('shuffling_array_1.p', 'wb'))\n",
    "pickle.dump(shuffling_array[20000:40000], open('shuffling_array_2.p', 'wb'))\n",
    "pickle.dump(shuffling_array[40000:60000], open('shuffling_array_3.p', 'wb'))\n",
    "pickle.dump(shuffling_array[60000:80000], open('shuffling_array_4.p', 'wb'))\n",
    "pickle.dump(shuffling_array[80000:100000], open('shuffling_array_5.p', 'wb'))\n",
    "pickle.dump(shuffling_array[100000:120000], open('shuffling_array_6.p', 'wb'))\n",
    "pickle.dump(shuffling_array[120000:], open('shuffling_array_7.p', 'wb'))\n",
    "\n",
    "shuffling_array_1 = pickle.load(open('shuffling_array_1.p', 'rb'))\n",
    "shuffling_array_2 = pickle.load(open('shuffling_array_2.p', 'rb'))\n",
    "shuffling_array_3 = pickle.load(open('shuffling_array_3.p', 'rb'))\n",
    "shuffling_array_4 = pickle.load(open('shuffling_array_4.p', 'rb'))\n",
    "shuffling_array_5 = pickle.load(open('shuffling_array_5.p', 'rb'))\n",
    "shuffling_array_6 = pickle.load(open('shuffling_array_6.p', 'rb'))\n",
    "shuffling_array_7 = pickle.load(open('shuffling_array_7.p', 'rb'))\n",
    "\n",
    "shuffling_array = np.append(shuffling_array_1 , np.append(shuffling_array_2 , np.append(shuffling_array_3 , np.append(shuffling_array_4 , np.append(shuffling_array_5 , np.append(shuffling_array_6 , shuffling_array_7 , axis = 0) , axis = 0) , axis = 0) , axis = 0) , axis = 0) , axis = 0)\n",
    "shuffling_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
